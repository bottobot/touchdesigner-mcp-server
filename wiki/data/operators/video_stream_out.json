{
  "id": "video_stream_out",
  "name": "Video Stream Out",
  "displayName": "Video Stream Out",
  "category": "TOP",
  "subcategory": "Filters",
  "version": "",
  "lastUpdated": "2025-08-08T00:37:55.874Z",
  "sourceFile": "C:\\Program Files\\Derivative\\TouchDesigner\\Samples\\Learn\\OfflineHelp\\https.docs.derivative.ca\\Video_Stream_Out_TOP.htm",
  "url": "",
  "description": "Note: This TOP uses the Nvidia Hardware Encoder to create the stream and therefore requires an Nvidia GPU and Windows to operate.",
  "summary": "Note: This TOP uses the Nvidia Hardware Encoder to create the stream and therefore requires an Nvidia GPU and Windows to operate.",
  "details": "",
  "usage": "",
  "tips": [],
  "warnings": [],
  "parameters": [
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "From Derivative\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\t\nNote: This  uses the Nvidia Hardware Encoder to create the stream and therefore requires an Nvidia  and Windows to operate.\nThe Video Stream Out  creates either an RTSP server, or can act as an RTMP or SRT sender, to send H.264 video and MP3 audio across the network. It uses Nvidia's hardware H264 encoder. For RTSP, it can handle multiple clients connecting to it at the same time. Multiple Video Stream Out TOPs using the same port will be handled using the same underlying RTSP server. The Video Stream Out  can also be used to send a video stream through WebRTC video/audio tracks.\t\n\n\nObtain the URL to connect to the Video Steam Out 's RTSP server by using an Info  or by middle clicking on the node. It will be in the form:\t\t\t\nrtsp://<ipaddress>:<port>/<streamName>\t\t\t\ne.g.\t\t\t\nrtsp://192.168.0.1:554/tdvidstream\t\t\t\n\n\nTo obtain the RTMP URL stream to, you may need to search to find the correct URL depending on your location and the service you are using. This should be in the format:\n{service url}/{stream key}. \nFor example for Twitch the URL would be something like\nrtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY\nFor more information on different services see RTMP.\n\n\nSRT can use either H.264 or H.265 video codec. It can also send per-frame metadata when a  or  is specified in the Per-Frame Metadata parameter. The SRT server is settings are controlled by URL options. E.g to create a listener you'd specify the URL:\nsrt://0.0.0.0:9494?mode=listener\nTo connect to listener, you'd do:\nsrt://127.0.0.1:9494?mode=caller\nEither side of the connection can be the listener or the caller, it doesn't matter which is sending the video and which is receiving the video. The receiver would set their mode to be the opposite of whatever the sender is setting their mode to be.\nAll the options that are available are listed here. Multiple options can be set using a & as separator. E.g\nsrt://127.0.0.1:9494?mode=caller&send_buffer_size=100000\nSRT sent from the Video Stream Out  can include per-frame metadata making it easy to send and receive / data in sync with video. It can be read with the Video Stream In TOP.\n\n\nRTSP streaming does not support sending directly to another RTSP server via RTP.\nThe maximum stream outs on a NVIDIA Geforce card is 2: The number of streams the  can handle is different depending on driver versions and hardware, however in general it is 2 streams max on Geforce level cards. Using a lower resolution does not avoid the 2 stream limit. Quadros can do more streams.\tRefer to Nvidia Video GPU Support Matrix for more information.\nOne test using the default TouchDesigner startup file on a M6000 was able to do 13 1080p@30hz Video Stream Out TOPs.\t\t\t\nSee also the Video Stream In TOP, RTMP, RTSP and Video Streaming User Guide.\t\t\t\nFor other protocols over IP see NDI (Network Data Interface), and Touch Out TOP / Touch In TOP.\nNOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.\nvideostreamoutTOP_Class\n\nContents\n \n \n \n \n \n\n \n \n \n \n \n \n \n \n\n\n\n\n\n  active - Controls if the server is active or not. If this is Off then the port this server uses will not be tied up.\n\n\n\n  mode -  - Selects if the mode works as an RTSP server, sends RTMP to a receiever such as a distribution service like YouTube or Twitch, or sends to an SRT destination.\n\n rtspserver - Use the RTSP and RTP protocol. More information here. rtmpsender - Use the RTMP protocol. More information here. srt - Use the SRT protocol. More information here. webrtc - Use a WebRTC peer. More info: WebRTC, WebRTC DAT.\n\n  port - The port the server should listen on. Multiple Video Stream Out TOPs can use the same port as long as each has a unique Stream Name.\n\n\n\n  streamname - The name of the stream for this node. This name is what comes after the / in the URL after the ipaddress:port combination.\n\n\n\n  multicast - Controls if RTSP server sends its video out using unicast or multicast UDP packets.\n\n\n\n  url - The URL to sent the RTMP stream to. This should be in the format of {service url}/{stream key}. For example for twitch the URL would be something like rtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY. You may need to search to find the correct URL depending on your location and the service you are using.\n\n\n\n  url - The URL to sent the RTMP stream to. This should be in the format of {service url}/{stream key}. For example for twitch the URL would be something like rtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY. You may need to search to find the correct URL depending on your location and the service you are using.\n\n\n\n  forceidr - For debugging, this will force the server to create a new video keyframe to send to all the clients. If clients aren't getting proper image this can be used to attempt to fix it. If you need to use this parameter please report the case to support@derivative.ca.\n\n\n\n  fps - The  to send video at.\n\n\n\n  videocodec -  - Select which codec to use for encoding the stream.\n\n h264nvgpu - h265nvgpu -\n\n  profile -  - The H.264 profile to use to encode the frames. Some decoders can only support H.264 encoder at certain profiles.\n\n baseline - main - high -\n\n  quality -  - The quality level of the encoding.\n\n lowlatencylow - lowlatencymedium - lowlatencyhigh - highlatencylow - highlatencyhigh -\n\n  keyframeinterval - Set the keyframe interval for the H.264 encoder.\n\n\n\n  maxbframes - The maximum number of bi-directional frames that can occur between keyframes. More will increase latency but reduce bandwidth.\n\n\n\n  intrarefreshperiod - Intra-refresh is a gradual keyframe that is applied across the image to clean up streaming artifacts over multiple frames, instead of one large keyframe. This controls the number of frames that elapse between each intra-refresh occuring.\n\n\n\n  intrarefreshlength - The number of frames the intra-refresh will be spread out across.\n\n\n\n  bitratemode -  - Chooses between constant (CBR) and variable (VBR) bit rate modes. Mode streaming services prefer a constant bit rate mode.\n\n constant - variable - constanthq - variablehq -\n\n  avgbitrate - The target bitrate for the encoding. This is specified in Mb/s (megabits/second).\n\n\n\n  perframemetadata - Send metadata from this OP with each frame of the video stream. This data can be received from the Video Stream In TOP using an Info CHOP and Info DAT.\n\n\n\n  maxbitrate - The maximum bitrate for the encoding. This is specified in Mb/s (megabits/second).\n\n\n\n  numslices - This controls how many pieces (slices) each H.264 frame is separated into. Some decoders are able to decode multiple slices simultaneously so setting this to a value above 1 allows those decoders to run more efficiently.\n\n\n\n  audiochop - A timesliced audio source to send along with the video. For RTSP, Audio will be resampled to 44100Hz before being encoded into MP3. For RTMP the sample rate must already be 44100. For WebRTC the sample rate must be 48000.\n\n\n\n  audiobitrate -  - Set the bit rate used for encoding audio.\n\n b96 - b128 - b192 - b256 - b320 -\n\n  includesilentaudio -  - Some broadcasting services require an audio stream to be included. This will include a silent audio stream along with the video in the event there isn't actual audio being streamed video the  parameter.\n\n automatic - on - off -\n\n  perframemetadata - Send metadata from this OP with each frame of the video stream. This data can be recevied from the Video Stream In TOP using an Info CHOP and Info DAT.\n\n\n\n\n\n  webrtc - Set the WebRTC DAT (ie. peer) to send the video stream over. Setting this will automatically populate the WebRTC Connection parameter menu with available connections.\n\n\n\n  webrtcconnection - Select the WebRTC peer-to-peer connection. Selecting this will automatically population the WebRTC Track parameter menu with available video output tracks.\n\n\n\n  webrtcvideotrack - Select the video output track that's a part of the WebRTC peer-to-peer connection.\n\n\n\n  webrtcaudiotrack - Optionally select the audio output track that's a part of the WebRTC peer-to-peer connection, to be sent along with the video.\n\n\n\n\n\n  outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Fits the width and height to the resolution given below, while maintaining the aspect ratio. limit - The width and height are limited to the resolution given below. If one of the dimensions exceeds the given resolution, the width and height will be reduced to fit inside the given limits while maintaining the aspect ratio. custom - Enables the  parameter below, giving direct control over width and height.\n\n  resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -\n\n  resmenu - A drop-down menu with some commonly used resolutions.\n\n\n\n  resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.\n\n\n\n  outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.\n\n  aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -\n\n  armenu - A drop-down menu with some commonly used aspect ratios.\n\n\n\n  inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.\n\n  filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  npasses - Duplicates the operation of the  the specified number of times. Making this larger than 1 is essentially the same as taking the output from each pass, and passing it into the first input of the node and repeating the process. Other inputs and parameters remain the same for each pass.\n\n\n\n  chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.\n\n\n\n  format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.\n\n\n\n -\n\nExtra Information for the Video Stream Out  can be accessed via an Info CHOP.\n\n\n - - -\n - Horizontal resolution of the  in pixels. - Vertical resolution of the  in pixels. - Horizontal aspect of the . - Vertical aspect of the . - Depth of 2D or 3D array if this  contains a 2D or 3D texture array. - Total amount of texture memory used by this .\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\nwikieditorwikieditorwikieditorwikieditor2022.241402021.100002020.236802018.28070before 2018.28070\nTOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family that creates, composites and modifies images, and reads/writes images and movies to/from files and the network. TOPs run on the graphics card's GPU.\n\n\n\nThe Graphics Processing Unit. This is the high-speed, many-core processor of the graphics card/chip that takes geometry, images and data from the CPU and creates images and processed data.\n\n\n\nAn Operator Family that manipulates text strings: multi-line text or tables. Multi-line text is often a python Script or GLSL Shader, but can be any multi-line text. Tables are rows and columns of cells, each containing a text string.\n\n\n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\nThe Frames-per-Second that TouchDesigner's Timeline runs at. Set with project.cookRate.\n\n\n\nIn the Animation component each keyframe specifies a channel's value at a specific time (or frame). A keyframe holds a value, slopes and accelerations, and an interpolation type. A channel's keyframes are used to interpolate and determine the values of all the samples of the channel.\n\n\n\nThe term \"Frame\" is a measurement of time used (1) in the Timeline, (2) as a time-unit in CHOPs, and (3) as a time unit in movie files that are read into TOPs and written out from TOPs. The frame rate is the frames per second (FPS).\n\n\n\nThe width and height of an image in pixels. Most TOPs, like the Movie File In TOP can set the image resolution. See Aspect Ratio for the width/height ratio of an image, taking into account non-square pixels.\n\n\n\nThe viewer of a node can be (1) the interior of a node (the Node Viewer), (2) a floating window (RMB->View... on node), or (3) a Pane that graphically shows the results of an operator.\n\n\n\nA CHOP outputs one or more channels, where a channel is simply a sequence of numbers (Samples), representing motion, audio, etc. Channels are passed between CHOPs in TouchDesigner networks. Channels can be Exported to Parameters.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=Video_Stream_Out_TOP&oldid=32429\"\n\t\tCategory: TOPs",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.864Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "From Derivative\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\t\nNote: This  uses the Nvidia Hardware Encoder to create the stream and therefore requires an Nvidia  and Windows to operate.\nThe Video Stream Out  creates either an RTSP server, or can act as an RTMP or SRT sender, to send H.264 video and MP3 audio across the network. It uses Nvidia's hardware H264 encoder. For RTSP, it can handle multiple clients connecting to it at the same time. Multiple Video Stream Out TOPs using the same port will be handled using the same underlying RTSP server. The Video Stream Out  can also be used to send a video stream through WebRTC video/audio tracks.\t\n\n\nObtain the URL to connect to the Video Steam Out 's RTSP server by using an Info  or by middle clicking on the node. It will be in the form:\t\t\t\nrtsp://<ipaddress>:<port>/<streamName>\t\t\t\ne.g.\t\t\t\nrtsp://192.168.0.1:554/tdvidstream\t\t\t\n\n\nTo obtain the RTMP URL stream to, you may need to search to find the correct URL depending on your location and the service you are using. This should be in the format:\n{service url}/{stream key}. \nFor example for Twitch the URL would be something like\nrtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY\nFor more information on different services see RTMP.\n\n\nSRT can use either H.264 or H.265 video codec. It can also send per-frame metadata when a  or  is specified in the Per-Frame Metadata parameter. The SRT server is settings are controlled by URL options. E.g to create a listener you'd specify the URL:\nsrt://0.0.0.0:9494?mode=listener\nTo connect to listener, you'd do:\nsrt://127.0.0.1:9494?mode=caller\nEither side of the connection can be the listener or the caller, it doesn't matter which is sending the video and which is receiving the video. The receiver would set their mode to be the opposite of whatever the sender is setting their mode to be.\nAll the options that are available are listed here. Multiple options can be set using a & as separator. E.g\nsrt://127.0.0.1:9494?mode=caller&send_buffer_size=100000\nSRT sent from the Video Stream Out  can include per-frame metadata making it easy to send and receive / data in sync with video. It can be read with the Video Stream In TOP.\n\n\nRTSP streaming does not support sending directly to another RTSP server via RTP.\nThe maximum stream outs on a NVIDIA Geforce card is 2: The number of streams the  can handle is different depending on driver versions and hardware, however in general it is 2 streams max on Geforce level cards. Using a lower resolution does not avoid the 2 stream limit. Quadros can do more streams.\tRefer to Nvidia Video GPU Support Matrix for more information.\nOne test using the default TouchDesigner startup file on a M6000 was able to do 13 1080p@30hz Video Stream Out TOPs.\t\t\t\nSee also the Video Stream In TOP, RTMP, RTSP and Video Streaming User Guide.\t\t\t\nFor other protocols over IP see NDI (Network Data Interface), and Touch Out TOP / Touch In TOP.\nNOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.\nvideostreamoutTOP_Class\n\nContents\n \n \n \n \n \n\n \n \n \n \n \n \n \n \n\n\n\n\n\n  active - Controls if the server is active or not. If this is Off then the port this server uses will not be tied up.\n\n\n\n  mode -  - Selects if the mode works as an RTSP server, sends RTMP to a receiever such as a distribution service like YouTube or Twitch, or sends to an SRT destination.\n\n rtspserver - Use the RTSP and RTP protocol. More information here. rtmpsender - Use the RTMP protocol. More information here. srt - Use the SRT protocol. More information here. webrtc - Use a WebRTC peer. More info: WebRTC, WebRTC DAT.\n\n  port - The port the server should listen on. Multiple Video Stream Out TOPs can use the same port as long as each has a unique Stream Name.\n\n\n\n  streamname - The name of the stream for this node. This name is what comes after the / in the URL after the ipaddress:port combination.\n\n\n\n  multicast - Controls if RTSP server sends its video out using unicast or multicast UDP packets.\n\n\n\n  url - The URL to sent the RTMP stream to. This should be in the format of {service url}/{stream key}. For example for twitch the URL would be something like rtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY. You may need to search to find the correct URL depending on your location and the service you are using.\n\n\n\n  url - The URL to sent the RTMP stream to. This should be in the format of {service url}/{stream key}. For example for twitch the URL would be something like rtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY. You may need to search to find the correct URL depending on your location and the service you are using.\n\n\n\n  forceidr - For debugging, this will force the server to create a new video keyframe to send to all the clients. If clients aren't getting proper image this can be used to attempt to fix it. If you need to use this parameter please report the case to support@derivative.ca.\n\n\n\n  fps - The  to send video at.\n\n\n\n  videocodec -  - Select which codec to use for encoding the stream.\n\n h264nvgpu - h265nvgpu -\n\n  profile -  - The H.264 profile to use to encode the frames. Some decoders can only support H.264 encoder at certain profiles.\n\n baseline - main - high -\n\n  quality -  - The quality level of the encoding.\n\n lowlatencylow - lowlatencymedium - lowlatencyhigh - highlatencylow - highlatencyhigh -\n\n  keyframeinterval - Set the keyframe interval for the H.264 encoder.\n\n\n\n  maxbframes - The maximum number of bi-directional frames that can occur between keyframes. More will increase latency but reduce bandwidth.\n\n\n\n  intrarefreshperiod - Intra-refresh is a gradual keyframe that is applied across the image to clean up streaming artifacts over multiple frames, instead of one large keyframe. This controls the number of frames that elapse between each intra-refresh occuring.\n\n\n\n  intrarefreshlength - The number of frames the intra-refresh will be spread out across.\n\n\n\n  bitratemode -  - Chooses between constant (CBR) and variable (VBR) bit rate modes. Mode streaming services prefer a constant bit rate mode.\n\n constant - variable - constanthq - variablehq -\n\n  avgbitrate - The target bitrate for the encoding. This is specified in Mb/s (megabits/second).\n\n\n\n  perframemetadata - Send metadata from this OP with each frame of the video stream. This data can be received from the Video Stream In TOP using an Info CHOP and Info DAT.\n\n\n\n  maxbitrate - The maximum bitrate for the encoding. This is specified in Mb/s (megabits/second).\n\n\n\n  numslices - This controls how many pieces (slices) each H.264 frame is separated into. Some decoders are able to decode multiple slices simultaneously so setting this to a value above 1 allows those decoders to run more efficiently.\n\n\n\n  audiochop - A timesliced audio source to send along with the video. For RTSP, Audio will be resampled to 44100Hz before being encoded into MP3. For RTMP the sample rate must already be 44100. For WebRTC the sample rate must be 48000.\n\n\n\n  audiobitrate -  - Set the bit rate used for encoding audio.\n\n b96 - b128 - b192 - b256 - b320 -\n\n  includesilentaudio -  - Some broadcasting services require an audio stream to be included. This will include a silent audio stream along with the video in the event there isn't actual audio being streamed video the  parameter.\n\n automatic - on - off -\n\n  perframemetadata - Send metadata from this OP with each frame of the video stream. This data can be recevied from the Video Stream In TOP using an Info CHOP and Info DAT.\n\n\n\n\n\n  webrtc - Set the WebRTC DAT (ie. peer) to send the video stream over. Setting this will automatically populate the WebRTC Connection parameter menu with available connections.\n\n\n\n  webrtcconnection - Select the WebRTC peer-to-peer connection. Selecting this will automatically population the WebRTC Track parameter menu with available video output tracks.\n\n\n\n  webrtcvideotrack - Select the video output track that's a part of the WebRTC peer-to-peer connection.\n\n\n\n  webrtcaudiotrack - Optionally select the audio output track that's a part of the WebRTC peer-to-peer connection, to be sent along with the video.\n\n\n\n\n\n  outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Fits the width and height to the resolution given below, while maintaining the aspect ratio. limit - The width and height are limited to the resolution given below. If one of the dimensions exceeds the given resolution, the width and height will be reduced to fit inside the given limits while maintaining the aspect ratio. custom - Enables the  parameter below, giving direct control over width and height.\n\n  resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -\n\n  resmenu - A drop-down menu with some commonly used resolutions.\n\n\n\n  resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.\n\n\n\n  outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.\n\n  aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -\n\n  armenu - A drop-down menu with some commonly used aspect ratios.\n\n\n\n  inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.\n\n  filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  npasses - Duplicates the operation of the  the specified number of times. Making this larger than 1 is essentially the same as taking the output from each pass, and passing it into the first input of the node and repeating the process. Other inputs and parameters remain the same for each pass.\n\n\n\n  chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.\n\n\n\n  format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.\n\n\n\n -\n\nExtra Information for the Video Stream Out  can be accessed via an Info CHOP.\n\n\n - - -\n - Horizontal resolution of the  in pixels. - Vertical resolution of the  in pixels. - Horizontal aspect of the . - Vertical aspect of the . - Depth of 2D or 3D array if this  contains a 2D or 3D texture array. - Total amount of texture memory used by this .\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\nwikieditorwikieditorwikieditorwikieditor2022.241402021.100002020.236802018.28070before 2018.28070\nTOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family that creates, composites and modifies images, and reads/writes images and movies to/from files and the network. TOPs run on the graphics card's GPU.\n\n\n\nThe Graphics Processing Unit. This is the high-speed, many-core processor of the graphics card/chip that takes geometry, images and data from the CPU and creates images and processed data.\n\n\n\nAn Operator Family that manipulates text strings: multi-line text or tables. Multi-line text is often a python Script or GLSL Shader, but can be any multi-line text. Tables are rows and columns of cells, each containing a text string.\n\n\n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\nThe Frames-per-Second that TouchDesigner's Timeline runs at. Set with project.cookRate.\n\n\n\nIn the Animation component each keyframe specifies a channel's value at a specific time (or frame). A keyframe holds a value, slopes and accelerations, and an interpolation type. A channel's keyframes are used to interpolate and determine the values of all the samples of the channel.\n\n\n\nThe term \"Frame\" is a measurement of time used (1) in the Timeline, (2) as a time-unit in CHOPs, and (3) as a time unit in movie files that are read into TOPs and written out from TOPs. The frame rate is the frames per second (FPS).\n\n\n\nThe width and height of an image in pixels. Most TOPs, like the Movie File In TOP can set the image resolution. See Aspect Ratio for the width/height ratio of an image, taking into account non-square pixels.\n\n\n\nThe viewer of a node can be (1) the interior of a node (the Node Viewer), (2) a floating window (RMB->View... on node), or (3) a Pane that graphically shows the results of an operator.\n\n\n\nA CHOP outputs one or more channels, where a channel is simply a sequence of numbers (Samples), representing motion, audio, etc. Channels are passed between CHOPs in TouchDesigner networks. Channels can be Exported to Parameters.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=Video_Stream_Out_TOP&oldid=32429\"\n\t\tCategory: TOPs",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.867Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "Note: This  uses the Nvidia Hardware Encoder to create the stream and therefore requires an Nvidia  and Windows to operate.\nThe Video Stream Out  creates either an RTSP server, or can act as an RTMP or SRT sender, to send H.264 video and MP3 audio across the network. It uses Nvidia's hardware H264 encoder. For RTSP, it can handle multiple clients connecting to it at the same time. Multiple Video Stream Out TOPs using the same port will be handled using the same underlying RTSP server. The Video Stream Out  can also be used to send a video stream through WebRTC video/audio tracks.\t\n\n\nObtain the URL to connect to the Video Steam Out 's RTSP server by using an Info  or by middle clicking on the node. It will be in the form:\t\t\t\nrtsp://<ipaddress>:<port>/<streamName>\t\t\t\ne.g.\t\t\t\nrtsp://192.168.0.1:554/tdvidstream\t\t\t\n\n\nTo obtain the RTMP URL stream to, you may need to search to find the correct URL depending on your location and the service you are using. This should be in the format:\n{service url}/{stream key}. \nFor example for Twitch the URL would be something like\nrtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY\nFor more information on different services see RTMP.\n\n\nSRT can use either H.264 or H.265 video codec. It can also send per-frame metadata when a  or  is specified in the Per-Frame Metadata parameter. The SRT server is settings are controlled by URL options. E.g to create a listener you'd specify the URL:\nsrt://0.0.0.0:9494?mode=listener\nTo connect to listener, you'd do:\nsrt://127.0.0.1:9494?mode=caller\nEither side of the connection can be the listener or the caller, it doesn't matter which is sending the video and which is receiving the video. The receiver would set their mode to be the opposite of whatever the sender is setting their mode to be.\nAll the options that are available are listed here. Multiple options can be set using a & as separator. E.g\nsrt://127.0.0.1:9494?mode=caller&send_buffer_size=100000\nSRT sent from the Video Stream Out  can include per-frame metadata making it easy to send and receive / data in sync with video. It can be read with the Video Stream In TOP.\n\n\nRTSP streaming does not support sending directly to another RTSP server via RTP.\nThe maximum stream outs on a NVIDIA Geforce card is 2: The number of streams the  can handle is different depending on driver versions and hardware, however in general it is 2 streams max on Geforce level cards. Using a lower resolution does not avoid the 2 stream limit. Quadros can do more streams.\tRefer to Nvidia Video GPU Support Matrix for more information.\nOne test using the default TouchDesigner startup file on a M6000 was able to do 13 1080p@30hz Video Stream Out TOPs.\t\t\t\nSee also the Video Stream In TOP, RTMP, RTSP and Video Streaming User Guide.\t\t\t\nFor other protocols over IP see NDI (Network Data Interface), and Touch Out TOP / Touch In TOP.\nNOTE for Windows OS - If experiencing connection issues make sure Windows Firewall is disabled.\nvideostreamoutTOP_Class\n\nContents\n \n \n \n \n \n\n \n \n \n \n \n \n \n \n\n\n\n\n\n  active - Controls if the server is active or not. If this is Off then the port this server uses will not be tied up.\n\n\n\n  mode -  - Selects if the mode works as an RTSP server, sends RTMP to a receiever such as a distribution service like YouTube or Twitch, or sends to an SRT destination.\n\n rtspserver - Use the RTSP and RTP protocol. More information here. rtmpsender - Use the RTMP protocol. More information here. srt - Use the SRT protocol. More information here. webrtc - Use a WebRTC peer. More info: WebRTC, WebRTC DAT.\n\n  port - The port the server should listen on. Multiple Video Stream Out TOPs can use the same port as long as each has a unique Stream Name.\n\n\n\n  streamname - The name of the stream for this node. This name is what comes after the / in the URL after the ipaddress:port combination.\n\n\n\n  multicast - Controls if RTSP server sends its video out using unicast or multicast UDP packets.\n\n\n\n  url - The URL to sent the RTMP stream to. This should be in the format of {service url}/{stream key}. For example for twitch the URL would be something like rtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY. You may need to search to find the correct URL depending on your location and the service you are using.\n\n\n\n  url - The URL to sent the RTMP stream to. This should be in the format of {service url}/{stream key}. For example for twitch the URL would be something like rtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY. You may need to search to find the correct URL depending on your location and the service you are using.\n\n\n\n  forceidr - For debugging, this will force the server to create a new video keyframe to send to all the clients. If clients aren't getting proper image this can be used to attempt to fix it. If you need to use this parameter please report the case to support@derivative.ca.\n\n\n\n  fps - The  to send video at.\n\n\n\n  videocodec -  - Select which codec to use for encoding the stream.\n\n h264nvgpu - h265nvgpu -\n\n  profile -  - The H.264 profile to use to encode the frames. Some decoders can only support H.264 encoder at certain profiles.\n\n baseline - main - high -\n\n  quality -  - The quality level of the encoding.\n\n lowlatencylow - lowlatencymedium - lowlatencyhigh - highlatencylow - highlatencyhigh -\n\n  keyframeinterval - Set the keyframe interval for the H.264 encoder.\n\n\n\n  maxbframes - The maximum number of bi-directional frames that can occur between keyframes. More will increase latency but reduce bandwidth.\n\n\n\n  intrarefreshperiod - Intra-refresh is a gradual keyframe that is applied across the image to clean up streaming artifacts over multiple frames, instead of one large keyframe. This controls the number of frames that elapse between each intra-refresh occuring.\n\n\n\n  intrarefreshlength - The number of frames the intra-refresh will be spread out across.\n\n\n\n  bitratemode -  - Chooses between constant (CBR) and variable (VBR) bit rate modes. Mode streaming services prefer a constant bit rate mode.\n\n constant - variable - constanthq - variablehq -\n\n  avgbitrate - The target bitrate for the encoding. This is specified in Mb/s (megabits/second).\n\n\n\n  perframemetadata - Send metadata from this OP with each frame of the video stream. This data can be received from the Video Stream In TOP using an Info CHOP and Info DAT.\n\n\n\n  maxbitrate - The maximum bitrate for the encoding. This is specified in Mb/s (megabits/second).\n\n\n\n  numslices - This controls how many pieces (slices) each H.264 frame is separated into. Some decoders are able to decode multiple slices simultaneously so setting this to a value above 1 allows those decoders to run more efficiently.\n\n\n\n  audiochop - A timesliced audio source to send along with the video. For RTSP, Audio will be resampled to 44100Hz before being encoded into MP3. For RTMP the sample rate must already be 44100. For WebRTC the sample rate must be 48000.\n\n\n\n  audiobitrate -  - Set the bit rate used for encoding audio.\n\n b96 - b128 - b192 - b256 - b320 -\n\n  includesilentaudio -  - Some broadcasting services require an audio stream to be included. This will include a silent audio stream along with the video in the event there isn't actual audio being streamed video the  parameter.\n\n automatic - on - off -\n\n  perframemetadata - Send metadata from this OP with each frame of the video stream. This data can be recevied from the Video Stream In TOP using an Info CHOP and Info DAT.\n\n\n\n\n\n  webrtc - Set the WebRTC DAT (ie. peer) to send the video stream over. Setting this will automatically populate the WebRTC Connection parameter menu with available connections.\n\n\n\n  webrtcconnection - Select the WebRTC peer-to-peer connection. Selecting this will automatically population the WebRTC Track parameter menu with available video output tracks.\n\n\n\n  webrtcvideotrack - Select the video output track that's a part of the WebRTC peer-to-peer connection.\n\n\n\n  webrtcaudiotrack - Optionally select the audio output track that's a part of the WebRTC peer-to-peer connection, to be sent along with the video.\n\n\n\n\n\n  outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Fits the width and height to the resolution given below, while maintaining the aspect ratio. limit - The width and height are limited to the resolution given below. If one of the dimensions exceeds the given resolution, the width and height will be reduced to fit inside the given limits while maintaining the aspect ratio. custom - Enables the  parameter below, giving direct control over width and height.\n\n  resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -\n\n  resmenu - A drop-down menu with some commonly used resolutions.\n\n\n\n  resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.\n\n\n\n  outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.\n\n  aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -\n\n  armenu - A drop-down menu with some commonly used aspect ratios.\n\n\n\n  inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.\n\n  filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  npasses - Duplicates the operation of the  the specified number of times. Making this larger than 1 is essentially the same as taking the output from each pass, and passing it into the first input of the node and repeating the process. Other inputs and parameters remain the same for each pass.\n\n\n\n  chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.\n\n\n\n  format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.\n\n\n\n -\n\nExtra Information for the Video Stream Out  can be accessed via an Info CHOP.\n\n\n - - -\n - Horizontal resolution of the  in pixels. - Vertical resolution of the  in pixels. - Horizontal aspect of the . - Vertical aspect of the . - Depth of 2D or 3D array if this  contains a 2D or 3D texture array. - Total amount of texture memory used by this .\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\nwikieditorwikieditorwikieditorwikieditor2022.241402021.100002020.236802018.28070before 2018.28070\nTOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family that creates, composites and modifies images, and reads/writes images and movies to/from files and the network. TOPs run on the graphics card's GPU.\n\n\n\nThe Graphics Processing Unit. This is the high-speed, many-core processor of the graphics card/chip that takes geometry, images and data from the CPU and creates images and processed data.\n\n\n\nAn Operator Family that manipulates text strings: multi-line text or tables. Multi-line text is often a python Script or GLSL Shader, but can be any multi-line text. Tables are rows and columns of cells, each containing a text string.\n\n\n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\nThe Frames-per-Second that TouchDesigner's Timeline runs at. Set with project.cookRate.\n\n\n\nIn the Animation component each keyframe specifies a channel's value at a specific time (or frame). A keyframe holds a value, slopes and accelerations, and an interpolation type. A channel's keyframes are used to interpolate and determine the values of all the samples of the channel.\n\n\n\nThe term \"Frame\" is a measurement of time used (1) in the Timeline, (2) as a time-unit in CHOPs, and (3) as a time unit in movie files that are read into TOPs and written out from TOPs. The frame rate is the frames per second (FPS).\n\n\n\nThe width and height of an image in pixels. Most TOPs, like the Movie File In TOP can set the image resolution. See Aspect Ratio for the width/height ratio of an image, taking into account non-square pixels.\n\n\n\nThe viewer of a node can be (1) the interior of a node (the Node Viewer), (2) a floating window (RMB->View... on node), or (3) a Pane that graphically shows the results of an operator.\n\n\n\nA CHOP outputs one or more channels, where a channel is simply a sequence of numbers (Samples), representing motion, audio, etc. Channels are passed between CHOPs in TouchDesigner networks. Channels can be Exported to Parameters.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=Video_Stream_Out_TOP&oldid=32429\"",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "active - Controls if the server is active or not. If this is Off then the port this server uses will not be tied up.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Mode",
      "label": "Mode",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "mode -  - Selects if the mode works as an RTSP server, sends RTMP to a receiever such as a distribution service like YouTube or Twitch, or sends to an SRT destination.\n\n rtspserver - Use the RTSP and RTP protocol. More information here. rtmpsender - Use the RTMP protocol. More information here. srt - Use the SRT protocol. More information here. webrtc - Use a WebRTC peer. More info: WebRTC, WebRTC DAT.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "RTSP Server",
      "label": "RTSP Server",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "rtspserver - Use the RTSP and RTP protocol. More information here. rtmpsender - Use the RTMP protocol. More information here. srt - Use the SRT protocol. More information here. webrtc - Use a WebRTC peer. More info: WebRTC, WebRTC DAT.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Network Port",
      "label": "Network Port",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "port - The port the server should listen on. Multiple Video Stream Out TOPs can use the same port as long as each has a unique Stream Name.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Stream Name",
      "label": "Stream Name",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "streamname - The name of the stream for this node. This name is what comes after the / in the URL after the ipaddress:port combination.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Multi-Cast",
      "label": "Multi-Cast",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "multicast - Controls if RTSP server sends its video out using unicast or multicast UDP packets.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "RTMP Destination URL",
      "label": "RTMP Destination URL",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "url - The URL to sent the RTMP stream to. This should be in the format of {service url}/{stream key}. For example for twitch the URL would be something like rtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY. You may need to search to find the correct URL depending on your location and the service you are using.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Destination URL",
      "label": "Destination URL",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "url - The URL to sent the RTMP stream to. This should be in the format of {service url}/{stream key}. For example for twitch the URL would be something like rtmp://live-yto.twitch.tv/app/live_1234567_sduhy3xJ1KJ34Eg6CjksdJLubFS7gtUY. You may need to search to find the correct URL depending on your location and the service you are using.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Force IDR",
      "label": "Force IDR",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "forceidr - For debugging, this will force the server to create a new video keyframe to send to all the clients. If clients aren't getting proper image this can be used to attempt to fix it. If you need to use this parameter please report the case to support@derivative.ca.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "FPS",
      "label": "FPS",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "fps - The  to send video at.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Video Codec",
      "label": "Video Codec",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "videocodec -  - Select which codec to use for encoding the stream.\n\n h264nvgpu - h265nvgpu -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "H.264 (NVIDIA GPU)",
      "label": "H.264 (NVIDIA GPU)",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "h264nvgpu - h265nvgpu -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Profile",
      "label": "Profile",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "profile -  - The H.264 profile to use to encode the frames. Some decoders can only support H.264 encoder at certain profiles.\n\n baseline - main - high -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Baseline",
      "label": "Baseline",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "baseline - main - high -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Quality",
      "label": "Quality",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "quality -  - The quality level of the encoding.\n\n lowlatencylow - lowlatencymedium - lowlatencyhigh - highlatencylow - highlatencyhigh -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.870Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Low-Latency Low",
      "label": "Low-Latency Low",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "lowlatencylow - lowlatencymedium - lowlatencyhigh - highlatencylow - highlatencyhigh -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Keyframe Interval",
      "label": "Keyframe Interval",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "keyframeinterval - Set the keyframe interval for the H.264 encoder.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Max B-Frames",
      "label": "Max B-Frames",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "maxbframes - The maximum number of bi-directional frames that can occur between keyframes. More will increase latency but reduce bandwidth.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Intra-Refresh Period",
      "label": "Intra-Refresh Period",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "intrarefreshperiod - Intra-refresh is a gradual keyframe that is applied across the image to clean up streaming artifacts over multiple frames, instead of one large keyframe. This controls the number of frames that elapse between each intra-refresh occuring.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Intra-Refresh Length",
      "label": "Intra-Refresh Length",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "intrarefreshlength - The number of frames the intra-refresh will be spread out across.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Bitrate Mode",
      "label": "Bitrate Mode",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "bitratemode -  - Chooses between constant (CBR) and variable (VBR) bit rate modes. Mode streaming services prefer a constant bit rate mode.\n\n constant - variable - constanthq - variablehq -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Constant (CBR)",
      "label": "Constant (CBR)",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "constant - variable - constanthq - variablehq -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Average Bitrate (Mb/s)",
      "label": "Average Bitrate (Mb/s)",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "avgbitrate - The target bitrate for the encoding. This is specified in Mb/s (megabits/second).",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Per-Frame Metadata",
      "label": "Per-Frame Metadata",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "perframemetadata - Send metadata from this OP with each frame of the video stream. This data can be received from the Video Stream In TOP using an Info CHOP and Info DAT.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Max Bitrate (Mb/s)",
      "label": "Max Bitrate (Mb/s)",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "maxbitrate - The maximum bitrate for the encoding. This is specified in Mb/s (megabits/second).",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Num H264 Slices per Frame",
      "label": "Num H264 Slices per Frame",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "numslices - This controls how many pieces (slices) each H.264 frame is separated into. Some decoders are able to decode multiple slices simultaneously so setting this to a value above 1 allows those decoders to run more efficiently.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Audio CHOP",
      "label": "Audio CHOP",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "audiochop - A timesliced audio source to send along with the video. For RTSP, Audio will be resampled to 44100Hz before being encoded into MP3. For RTMP the sample rate must already be 44100. For WebRTC the sample rate must be 48000.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Audio Bit Rate",
      "label": "Audio Bit Rate",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "audiobitrate -  - Set the bit rate used for encoding audio.\n\n b96 - b128 - b192 - b256 - b320 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "96 kb/s",
      "label": "96 kb/s",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "b96 - b128 - b192 - b256 - b320 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Include Silent Audio Stream",
      "label": "Include Silent Audio Stream",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "includesilentaudio -  - Some broadcasting services require an audio stream to be included. This will include a silent audio stream along with the video in the event there isn't actual audio being streamed video the  parameter.\n\n automatic - on - off -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Automatic",
      "label": "Automatic",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "automatic - on - off -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Per-Frame Metadata CHOP/DAT",
      "label": "Per-Frame Metadata CHOP/DAT",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "perframemetadata - Send metadata from this OP with each frame of the video stream. This data can be recevied from the Video Stream In TOP using an Info CHOP and Info DAT.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "WebRTC",
      "label": "WebRTC",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "webrtc - Set the WebRTC DAT (ie. peer) to send the video stream over. Setting this will automatically populate the WebRTC Connection parameter menu with available connections.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.871Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "WebRTC Connection",
      "label": "WebRTC Connection",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "webrtcconnection - Select the WebRTC peer-to-peer connection. Selecting this will automatically population the WebRTC Track parameter menu with available video output tracks.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "WebRTC Video Track",
      "label": "WebRTC Video Track",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "webrtcvideotrack - Select the video output track that's a part of the WebRTC peer-to-peer connection.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "WebRTC Audio Track",
      "label": "WebRTC Audio Track",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "webrtcaudiotrack - Optionally select the audio output track that's a part of the WebRTC peer-to-peer connection, to be sent along with the video.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Output Resolution",
      "label": "Output Resolution",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Fits the width and height to the resolution given below, while maintaining the aspect ratio. limit - The width and height are limited to the resolution given below. If one of the dimensions exceeds the given resolution, the width and height will be reduced to fit inside the given limits while maintaining the aspect ratio. custom - Enables the  parameter below, giving direct control over width and height.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Fits the width and height to the resolution given below, while maintaining the aspect ratio. limit - The width and height are limited to the resolution given below. If one of the dimensions exceeds the given resolution, the width and height will be reduced to fit inside the given limits while maintaining the aspect ratio. custom - Enables the  parameter below, giving direct control over width and height.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Resolution",
      "label": "Resolution",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "W",
      "label": "W",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resolutionw - resolutionh -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Resolution Menu",
      "label": "Resolution Menu",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resmenu - A drop-down menu with some commonly used resolutions.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Global Res Multiplier",
      "label": "Use Global Res Multiplier",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Output Aspect",
      "label": "Output Aspect",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Aspect",
      "label": "Aspect",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Aspect1",
      "label": "Aspect1",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "aspect1 - aspect2 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.872Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Aspect Menu",
      "label": "Aspect Menu",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "armenu - A drop-down menu with some commonly used aspect ratios.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.873Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Input Smoothness",
      "label": "Input Smoothness",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.873Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Nearest Pixel",
      "label": "Nearest Pixel",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.873Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Fill Viewer",
      "label": "Fill Viewer",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.873Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.873Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Viewer Smoothness",
      "label": "Viewer Smoothness",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.873Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Nearest Pixel",
      "label": "Nearest Pixel",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.873Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Passes",
      "label": "Passes",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "npasses - Duplicates the operation of the  the specified number of times. Making this larger than 1 is essentially the same as taking the output from each pass, and passing it into the first input of the node and repeating the process. Other inputs and parameters remain the same for each pass.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.873Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Channel Mask",
      "label": "Channel Mask",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.873Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Pixel Format",
      "label": "Pixel Format",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.873Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:55.874Z",
      "rawData": {},
      "sourceElement": null
    }
  ],
  "parameterGroups": {},
  "codeExamples": [],
  "pythonExamples": [],
  "expressions": [],
  "commonInputs": [],
  "commonOutputs": [],
  "relatedOperators": [],
  "workflowPatterns": [],
  "images": [],
  "videos": [],
  "assets": [],
  "keywords": [
    "video",
    "stream",
    "out",
    "note:",
    "uses",
    "nvidia",
    "hardware",
    "encoder",
    "create",
    "therefore",
    "requires"
  ],
  "tags": [
    "TOP",
    "TouchDesigner",
    "Video Stream Out"
  ],
  "searchWeight": 1,
  "contentHash": "",
  "processingDate": "2025-08-08T00:37:55.874Z",
  "processingVersion": "1.0.0",
  "isValid": true,
  "validationErrors": []
}