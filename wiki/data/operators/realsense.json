{
  "id": "realsense",
  "name": "RealSense",
  "displayName": "RealSense",
  "category": "TOP",
  "subcategory": "Filters",
  "version": "",
  "lastUpdated": "2025-08-08T00:37:51.750Z",
  "sourceFile": "C:\\Program Files\\Derivative\\TouchDesigner\\Samples\\Learn\\OfflineHelp\\https.docs.derivative.ca\\RealSense_TOP.htm",
  "url": "",
  "description": "Hardware: The librealsense SDK v2.50.0 does not look like it will be updated for Apple Silicon, so it is not an option to add to these builds.",
  "summary": "Hardware: The librealsense SDK v2.50.0 does not look like it will be updated for Apple Silicon, so it is not an option to add to these builds.",
  "details": "",
  "usage": "",
  "tips": [],
  "warnings": [],
  "parameters": [
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "From Derivative\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\t\nNOTE\n\nHardware: The librealsense SDK v2.50.0 does not look like it will be updated for Apple Silicon, so it is not an option to add to these builds.\n\n\n\nRealSense is a tracking device from Intel. The RealSense  connects to Intel RealSense devices and outputs color, depth and IR data from it.\nSee also RealSense for hardware information and installation instruction, and the RealSense CHOP.\nrealsenseTOP_Class\n\nContents\n \n \n \n \n \n \n \n\n\n\n\n\n  active - When set to 1 the  captures the image stream from the camera.\n\n\n\n  model -  - Select the model of device to use.\n\n f200 - r200 - zr300 - sr300 - sr305 - d415 - d435 - d435i -\n d435i - t265 - l515 -\n\t\t\n  sensor - Select which device to use.\n\n\n\t\t\n  image -  - Select the image type to output.\n\n color - The video from the color sensor. depth - The calculated depth value for each pixel. The data is re-range to be between 0 and the 'Max Depth' parameter, specified in Meters. A pixel value of 0 means 0 meters from the camera while a pixel value of 1 means 'Max Depth' or more pixels from the camera. rawdepth - The raw depth value for each pixel from the SDK. Not well documented by the SDK. The data is re-range to be between 0 and the 'Max Depth' parameter, specified in Meters. A pixel value of 0 means 0 meters from the camera while a pixel value of 1 means 'Max Depth' or more pixels from the camera. depthalignedtocolor - Outputs the depth image adjusted to match the uv of the color image. (RealSense Cross Platform API only) coloralignedtodepth - Outputs the color image adjusted to match the uv of the depth image. (RealSense Cross Platform API only) infrared - The raw video from the infrared sensor. pointcloud - Literally a cloud of points in 3d space (X, Y, Z coordinates) or data points created by the scanner of the RealSense Camera. pointcloudcoloruv - Which can be used to get each point’s color from the Color image stream. visualizeddepth - The depth values as output from the SDK when requesting a RGBA image. This output is useful for visualizing the depth, but the pixels values are dyanmically re-ranged by the SDK so it can't be used to determine a pixel's actual depth from the camera. (RealSense SDK for Windows only) depthtocoloruv - A RG 32-bit float texture that is the UV values needed to remap the Depth image to line up with the Color image. Use a Remap TOP with this and the Depth image to produce something that will be aligned with the Color image. (RealSense SDK for Windows only) colortodepthuv - A RG 32-bit float texture that is the UV values needed to remap the Color image to line up with the Depth image. Use a Remap TOP with this and the Color image to produce something that will be aligned with the Depth image. (RealSense SDK for Windows only) segmentedcolor - Which outputs masked color image of the detected person in front of the camera. (RealSense SDK for Windows only) fisheye - (RealSense SDK for Windows only)\n\t\t\n  colorres - Select the resolution of the video. Currently only usable for the Color image.\n\n\n\t\t\n  maxdepth - The depth value pixels with a value of 1 will be set to. Specified in Meters. Pixels with a depth larger than this will be clamped to 1 for fixed point texture output, or go above 1 for floating point output.\n\n\n\t\t\n  mirrorimage - Flip the image horizontally.\n\n\n\t\t\n  defaulttradeoff - Use the default Motion Range Tradeoff specified by the device.\n\n\n\n  tradeoff - Specifies the tradeoff between motion and range. Value is from 0 (short exposure, short range, and better motion) to 100 (long exposure and long range).\n\n\n\n  optionschop - Channels specified in this  allow for setting all of the options that the RealSense camera supports. Channel names should be the same as the C enumeration, with the RS2_OPTION_ prefix removed, and all lowercase. E.g RS2_OPTION_ENABLE_AUTO_EXPOSURE can be set by using a channel named \"enable_auto_exposure\". A list of options can be found here.\n\n\n\n  skeltracking - When enabled, performs skeleton tracking using the Cubemos Skeleton Tracking API. The results can be fetched via the RealSense CHOP. A Cubemos license is required for usage. A trial license is available.\n\n\n\n  usedefaultpaths - When enabled, will search for the license and model files in the default location (LOCALAPPDATA). For the files to appear there the Cubemos SDK will need to be installed. If a specific license directory or model file is desired then this can be disabled.\n\n\n\n  licensedir - Specify the directory with the license files (activation_key.json and cubemos_license.json).\n\n\n\n  modelfile - Specify the model file (.cubemos)\n\n\n\n\n\n  outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Grow or shrink the input resolution to fit this resolution, while keeping the aspect ratio the same. limit - Limit the input resolution to be not larger than this resolution, while keeping the aspect ratio the same. custom - Directly control the width and height.\n\n  resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -\n\n  resmenu - A drop-down menu with some commonly used resolutions.\n\n\n\n  resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.\n\n\n\n  outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.\n\n  aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -\n\n  armenu - A drop-down menu with some commonly used aspect ratios.\n\n\n\n  inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.\n\n  filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail. When the input is 32-bit float format, only nearest filtering will be used (regardless of what is selected).\n\n  npasses - Duplicates the operation of the  the specified number of times. For every pass after the first it takes the result of the previous pass and replaces the node's first input with the result of the previous pass. One exception to this is the GLSL TOP when using compute shaders, where the input will continue to be the connected 's image.\n\n\n\n  chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.\n\n\n\n  format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. Note that this does not apply an sRGB curve to the pixel values, it only stores them using an sRGB curve. This means more data is used for the darker values and less for the brighter values. When the values are read downstream they will be converted back to linear. For more information refer to sRGB. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.\n\n\n\nExtra Information for the RealSense  can be accessed via an Info CHOP.\n\n\n -\n - Horizontal resolution of the  in pixels. - Vertical resolution of the  in pixels. - Horizontal aspect of the . - Vertical aspect of the . - Depth of 2D or 3D array if this  contains a 2D or 3D texture array. - Total amount of texture memory used by this .\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\nwikieditorwikieditorwikieditor2021.100002018.28070before 2018.28070\nTOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family that creates, composites and modifies images, and reads/writes images and movies to/from files and the network. TOPs run on the graphics card's GPU.\n\n\n\nEach SOP has a list of Points. Each point has an XYZ 3D position value plus other optional attributes. Each polygon Primitive is defined by a vertex list, which is list of point numbers.\n\n\n\nThe width and height of an image in pixels. Most TOPs, like the Movie File In TOP can set the image resolution. See Aspect Ratio for the width/height ratio of an image, taking into account non-square pixels.\n\n\n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\nThe viewer of a node can be (1) the interior of a node (the Node Viewer), (2) a floating window (RMB->View... on node), or (3) a Pane that graphically shows the results of an operator.\n\n\n\nA CHOP outputs one or more channels, where a channel is simply a sequence of numbers (Samples), representing motion, audio, etc. Channels are passed between CHOPs in TouchDesigner networks. Channels can be Exported to Parameters.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=RealSense_TOP&oldid=28625\"\n\t\tCategory: TOPs",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.740Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "From Derivative\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\t\nNOTE\n\nHardware: The librealsense SDK v2.50.0 does not look like it will be updated for Apple Silicon, so it is not an option to add to these builds.\n\n\n\nRealSense is a tracking device from Intel. The RealSense  connects to Intel RealSense devices and outputs color, depth and IR data from it.\nSee also RealSense for hardware information and installation instruction, and the RealSense CHOP.\nrealsenseTOP_Class\n\nContents\n \n \n \n \n \n \n \n\n\n\n\n\n  active - When set to 1 the  captures the image stream from the camera.\n\n\n\n  model -  - Select the model of device to use.\n\n f200 - r200 - zr300 - sr300 - sr305 - d415 - d435 - d435i -\n d435i - t265 - l515 -\n\t\t\n  sensor - Select which device to use.\n\n\n\t\t\n  image -  - Select the image type to output.\n\n color - The video from the color sensor. depth - The calculated depth value for each pixel. The data is re-range to be between 0 and the 'Max Depth' parameter, specified in Meters. A pixel value of 0 means 0 meters from the camera while a pixel value of 1 means 'Max Depth' or more pixels from the camera. rawdepth - The raw depth value for each pixel from the SDK. Not well documented by the SDK. The data is re-range to be between 0 and the 'Max Depth' parameter, specified in Meters. A pixel value of 0 means 0 meters from the camera while a pixel value of 1 means 'Max Depth' or more pixels from the camera. depthalignedtocolor - Outputs the depth image adjusted to match the uv of the color image. (RealSense Cross Platform API only) coloralignedtodepth - Outputs the color image adjusted to match the uv of the depth image. (RealSense Cross Platform API only) infrared - The raw video from the infrared sensor. pointcloud - Literally a cloud of points in 3d space (X, Y, Z coordinates) or data points created by the scanner of the RealSense Camera. pointcloudcoloruv - Which can be used to get each point’s color from the Color image stream. visualizeddepth - The depth values as output from the SDK when requesting a RGBA image. This output is useful for visualizing the depth, but the pixels values are dyanmically re-ranged by the SDK so it can't be used to determine a pixel's actual depth from the camera. (RealSense SDK for Windows only) depthtocoloruv - A RG 32-bit float texture that is the UV values needed to remap the Depth image to line up with the Color image. Use a Remap TOP with this and the Depth image to produce something that will be aligned with the Color image. (RealSense SDK for Windows only) colortodepthuv - A RG 32-bit float texture that is the UV values needed to remap the Color image to line up with the Depth image. Use a Remap TOP with this and the Color image to produce something that will be aligned with the Depth image. (RealSense SDK for Windows only) segmentedcolor - Which outputs masked color image of the detected person in front of the camera. (RealSense SDK for Windows only) fisheye - (RealSense SDK for Windows only)\n\t\t\n  colorres - Select the resolution of the video. Currently only usable for the Color image.\n\n\n\t\t\n  maxdepth - The depth value pixels with a value of 1 will be set to. Specified in Meters. Pixels with a depth larger than this will be clamped to 1 for fixed point texture output, or go above 1 for floating point output.\n\n\n\t\t\n  mirrorimage - Flip the image horizontally.\n\n\n\t\t\n  defaulttradeoff - Use the default Motion Range Tradeoff specified by the device.\n\n\n\n  tradeoff - Specifies the tradeoff between motion and range. Value is from 0 (short exposure, short range, and better motion) to 100 (long exposure and long range).\n\n\n\n  optionschop - Channels specified in this  allow for setting all of the options that the RealSense camera supports. Channel names should be the same as the C enumeration, with the RS2_OPTION_ prefix removed, and all lowercase. E.g RS2_OPTION_ENABLE_AUTO_EXPOSURE can be set by using a channel named \"enable_auto_exposure\". A list of options can be found here.\n\n\n\n  skeltracking - When enabled, performs skeleton tracking using the Cubemos Skeleton Tracking API. The results can be fetched via the RealSense CHOP. A Cubemos license is required for usage. A trial license is available.\n\n\n\n  usedefaultpaths - When enabled, will search for the license and model files in the default location (LOCALAPPDATA). For the files to appear there the Cubemos SDK will need to be installed. If a specific license directory or model file is desired then this can be disabled.\n\n\n\n  licensedir - Specify the directory with the license files (activation_key.json and cubemos_license.json).\n\n\n\n  modelfile - Specify the model file (.cubemos)\n\n\n\n\n\n  outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Grow or shrink the input resolution to fit this resolution, while keeping the aspect ratio the same. limit - Limit the input resolution to be not larger than this resolution, while keeping the aspect ratio the same. custom - Directly control the width and height.\n\n  resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -\n\n  resmenu - A drop-down menu with some commonly used resolutions.\n\n\n\n  resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.\n\n\n\n  outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.\n\n  aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -\n\n  armenu - A drop-down menu with some commonly used aspect ratios.\n\n\n\n  inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.\n\n  filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail. When the input is 32-bit float format, only nearest filtering will be used (regardless of what is selected).\n\n  npasses - Duplicates the operation of the  the specified number of times. For every pass after the first it takes the result of the previous pass and replaces the node's first input with the result of the previous pass. One exception to this is the GLSL TOP when using compute shaders, where the input will continue to be the connected 's image.\n\n\n\n  chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.\n\n\n\n  format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. Note that this does not apply an sRGB curve to the pixel values, it only stores them using an sRGB curve. This means more data is used for the darker values and less for the brighter values. When the values are read downstream they will be converted back to linear. For more information refer to sRGB. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.\n\n\n\nExtra Information for the RealSense  can be accessed via an Info CHOP.\n\n\n -\n - Horizontal resolution of the  in pixels. - Vertical resolution of the  in pixels. - Horizontal aspect of the . - Vertical aspect of the . - Depth of 2D or 3D array if this  contains a 2D or 3D texture array. - Total amount of texture memory used by this .\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\nwikieditorwikieditorwikieditor2021.100002018.28070before 2018.28070\nTOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family that creates, composites and modifies images, and reads/writes images and movies to/from files and the network. TOPs run on the graphics card's GPU.\n\n\n\nEach SOP has a list of Points. Each point has an XYZ 3D position value plus other optional attributes. Each polygon Primitive is defined by a vertex list, which is list of point numbers.\n\n\n\nThe width and height of an image in pixels. Most TOPs, like the Movie File In TOP can set the image resolution. See Aspect Ratio for the width/height ratio of an image, taking into account non-square pixels.\n\n\n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\nThe viewer of a node can be (1) the interior of a node (the Node Viewer), (2) a floating window (RMB->View... on node), or (3) a Pane that graphically shows the results of an operator.\n\n\n\nA CHOP outputs one or more channels, where a channel is simply a sequence of numbers (Samples), representing motion, audio, etc. Channels are passed between CHOPs in TouchDesigner networks. Channels can be Exported to Parameters.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=RealSense_TOP&oldid=28625\"\n\t\tCategory: TOPs",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.743Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "NOTE\n\nHardware: The librealsense SDK v2.50.0 does not look like it will be updated for Apple Silicon, so it is not an option to add to these builds.\n\n\n\nRealSense is a tracking device from Intel. The RealSense  connects to Intel RealSense devices and outputs color, depth and IR data from it.\nSee also RealSense for hardware information and installation instruction, and the RealSense CHOP.\nrealsenseTOP_Class\n\nContents\n \n \n \n \n \n \n \n\n\n\n\n\n  active - When set to 1 the  captures the image stream from the camera.\n\n\n\n  model -  - Select the model of device to use.\n\n f200 - r200 - zr300 - sr300 - sr305 - d415 - d435 - d435i -\n d435i - t265 - l515 -\n\t\t\n  sensor - Select which device to use.\n\n\n\t\t\n  image -  - Select the image type to output.\n\n color - The video from the color sensor. depth - The calculated depth value for each pixel. The data is re-range to be between 0 and the 'Max Depth' parameter, specified in Meters. A pixel value of 0 means 0 meters from the camera while a pixel value of 1 means 'Max Depth' or more pixels from the camera. rawdepth - The raw depth value for each pixel from the SDK. Not well documented by the SDK. The data is re-range to be between 0 and the 'Max Depth' parameter, specified in Meters. A pixel value of 0 means 0 meters from the camera while a pixel value of 1 means 'Max Depth' or more pixels from the camera. depthalignedtocolor - Outputs the depth image adjusted to match the uv of the color image. (RealSense Cross Platform API only) coloralignedtodepth - Outputs the color image adjusted to match the uv of the depth image. (RealSense Cross Platform API only) infrared - The raw video from the infrared sensor. pointcloud - Literally a cloud of points in 3d space (X, Y, Z coordinates) or data points created by the scanner of the RealSense Camera. pointcloudcoloruv - Which can be used to get each point’s color from the Color image stream. visualizeddepth - The depth values as output from the SDK when requesting a RGBA image. This output is useful for visualizing the depth, but the pixels values are dyanmically re-ranged by the SDK so it can't be used to determine a pixel's actual depth from the camera. (RealSense SDK for Windows only) depthtocoloruv - A RG 32-bit float texture that is the UV values needed to remap the Depth image to line up with the Color image. Use a Remap TOP with this and the Depth image to produce something that will be aligned with the Color image. (RealSense SDK for Windows only) colortodepthuv - A RG 32-bit float texture that is the UV values needed to remap the Color image to line up with the Depth image. Use a Remap TOP with this and the Color image to produce something that will be aligned with the Depth image. (RealSense SDK for Windows only) segmentedcolor - Which outputs masked color image of the detected person in front of the camera. (RealSense SDK for Windows only) fisheye - (RealSense SDK for Windows only)\n\t\t\n  colorres - Select the resolution of the video. Currently only usable for the Color image.\n\n\n\t\t\n  maxdepth - The depth value pixels with a value of 1 will be set to. Specified in Meters. Pixels with a depth larger than this will be clamped to 1 for fixed point texture output, or go above 1 for floating point output.\n\n\n\t\t\n  mirrorimage - Flip the image horizontally.\n\n\n\t\t\n  defaulttradeoff - Use the default Motion Range Tradeoff specified by the device.\n\n\n\n  tradeoff - Specifies the tradeoff between motion and range. Value is from 0 (short exposure, short range, and better motion) to 100 (long exposure and long range).\n\n\n\n  optionschop - Channels specified in this  allow for setting all of the options that the RealSense camera supports. Channel names should be the same as the C enumeration, with the RS2_OPTION_ prefix removed, and all lowercase. E.g RS2_OPTION_ENABLE_AUTO_EXPOSURE can be set by using a channel named \"enable_auto_exposure\". A list of options can be found here.\n\n\n\n  skeltracking - When enabled, performs skeleton tracking using the Cubemos Skeleton Tracking API. The results can be fetched via the RealSense CHOP. A Cubemos license is required for usage. A trial license is available.\n\n\n\n  usedefaultpaths - When enabled, will search for the license and model files in the default location (LOCALAPPDATA). For the files to appear there the Cubemos SDK will need to be installed. If a specific license directory or model file is desired then this can be disabled.\n\n\n\n  licensedir - Specify the directory with the license files (activation_key.json and cubemos_license.json).\n\n\n\n  modelfile - Specify the model file (.cubemos)\n\n\n\n\n\n  outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Grow or shrink the input resolution to fit this resolution, while keeping the aspect ratio the same. limit - Limit the input resolution to be not larger than this resolution, while keeping the aspect ratio the same. custom - Directly control the width and height.\n\n  resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -\n\n  resmenu - A drop-down menu with some commonly used resolutions.\n\n\n\n  resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.\n\n\n\n  outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.\n\n  aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -\n\n  armenu - A drop-down menu with some commonly used aspect ratios.\n\n\n\n  inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.\n\n  filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail. When the input is 32-bit float format, only nearest filtering will be used (regardless of what is selected).\n\n  npasses - Duplicates the operation of the  the specified number of times. For every pass after the first it takes the result of the previous pass and replaces the node's first input with the result of the previous pass. One exception to this is the GLSL TOP when using compute shaders, where the input will continue to be the connected 's image.\n\n\n\n  chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.\n\n\n\n  format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. Note that this does not apply an sRGB curve to the pixel values, it only stores them using an sRGB curve. This means more data is used for the darker values and less for the brighter values. When the values are read downstream they will be converted back to linear. For more information refer to sRGB. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.\n\n\n\nExtra Information for the RealSense  can be accessed via an Info CHOP.\n\n\n -\n - Horizontal resolution of the  in pixels. - Vertical resolution of the  in pixels. - Horizontal aspect of the . - Vertical aspect of the . - Depth of 2D or 3D array if this  contains a 2D or 3D texture array. - Total amount of texture memory used by this .\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\nwikieditorwikieditorwikieditor2021.100002018.28070before 2018.28070\nTOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family that creates, composites and modifies images, and reads/writes images and movies to/from files and the network. TOPs run on the graphics card's GPU.\n\n\n\nEach SOP has a list of Points. Each point has an XYZ 3D position value plus other optional attributes. Each polygon Primitive is defined by a vertex list, which is list of point numbers.\n\n\n\nThe width and height of an image in pixels. Most TOPs, like the Movie File In TOP can set the image resolution. See Aspect Ratio for the width/height ratio of an image, taking into account non-square pixels.\n\n\n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\nThe viewer of a node can be (1) the interior of a node (the Node Viewer), (2) a floating window (RMB->View... on node), or (3) a Pane that graphically shows the results of an operator.\n\n\n\nA CHOP outputs one or more channels, where a channel is simply a sequence of numbers (Samples), representing motion, audio, etc. Channels are passed between CHOPs in TouchDesigner networks. Channels can be Exported to Parameters.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=RealSense_TOP&oldid=28625\"",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.745Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "active - When set to 1 the  captures the image stream from the camera.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.746Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Model",
      "label": "Model",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "model -  - Select the model of device to use.\n\n f200 - r200 - zr300 - sr300 - sr305 - d415 - d435 - d435i -\n d435i - t265 - l515 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.746Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "F200",
      "label": "F200",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "f200 - r200 - zr300 - sr300 - sr305 - d415 - d435 - d435i -\n d435i - t265 - l515 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.746Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Sensor",
      "label": "Sensor",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "sensor - Select which device to use.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.746Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Image",
      "label": "Image",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "image -  - Select the image type to output.\n\n color - The video from the color sensor. depth - The calculated depth value for each pixel. The data is re-range to be between 0 and the 'Max Depth' parameter, specified in Meters. A pixel value of 0 means 0 meters from the camera while a pixel value of 1 means 'Max Depth' or more pixels from the camera. rawdepth - The raw depth value for each pixel from the SDK. Not well documented by the SDK. The data is re-range to be between 0 and the 'Max Depth' parameter, specified in Meters. A pixel value of 0 means 0 meters from the camera while a pixel value of 1 means 'Max Depth' or more pixels from the camera. depthalignedtocolor - Outputs the depth image adjusted to match the uv of the color image. (RealSense Cross Platform API only) coloralignedtodepth - Outputs the color image adjusted to match the uv of the depth image. (RealSense Cross Platform API only) infrared - The raw video from the infrared sensor. pointcloud - Literally a cloud of points in 3d space (X, Y, Z coordinates) or data points created by the scanner of the RealSense Camera. pointcloudcoloruv - Which can be used to get each point’s color from the Color image stream. visualizeddepth - The depth values as output from the SDK when requesting a RGBA image. This output is useful for visualizing the depth, but the pixels values are dyanmically re-ranged by the SDK so it can't be used to determine a pixel's actual depth from the camera. (RealSense SDK for Windows only) depthtocoloruv - A RG 32-bit float texture that is the UV values needed to remap the Depth image to line up with the Color image. Use a Remap TOP with this and the Depth image to produce something that will be aligned with the Color image. (RealSense SDK for Windows only) colortodepthuv - A RG 32-bit float texture that is the UV values needed to remap the Color image to line up with the Depth image. Use a Remap TOP with this and the Color image to produce something that will be aligned with the Depth image. (RealSense SDK for Windows only) segmentedcolor - Which outputs masked color image of the detected person in front of the camera. (RealSense SDK for Windows only) fisheye - (RealSense SDK for Windows only)",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.746Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Color",
      "label": "Color",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "color - The video from the color sensor. depth - The calculated depth value for each pixel. The data is re-range to be between 0 and the 'Max Depth' parameter, specified in Meters. A pixel value of 0 means 0 meters from the camera while a pixel value of 1 means 'Max Depth' or more pixels from the camera. rawdepth - The raw depth value for each pixel from the SDK. Not well documented by the SDK. The data is re-range to be between 0 and the 'Max Depth' parameter, specified in Meters. A pixel value of 0 means 0 meters from the camera while a pixel value of 1 means 'Max Depth' or more pixels from the camera. depthalignedtocolor - Outputs the depth image adjusted to match the uv of the color image. (RealSense Cross Platform API only) coloralignedtodepth - Outputs the color image adjusted to match the uv of the depth image. (RealSense Cross Platform API only) infrared - The raw video from the infrared sensor. pointcloud - Literally a cloud of points in 3d space (X, Y, Z coordinates) or data points created by the scanner of the RealSense Camera. pointcloudcoloruv - Which can be used to get each point’s color from the Color image stream. visualizeddepth - The depth values as output from the SDK when requesting a RGBA image. This output is useful for visualizing the depth, but the pixels values are dyanmically re-ranged by the SDK so it can't be used to determine a pixel's actual depth from the camera. (RealSense SDK for Windows only) depthtocoloruv - A RG 32-bit float texture that is the UV values needed to remap the Depth image to line up with the Color image. Use a Remap TOP with this and the Depth image to produce something that will be aligned with the Color image. (RealSense SDK for Windows only) colortodepthuv - A RG 32-bit float texture that is the UV values needed to remap the Color image to line up with the Depth image. Use a Remap TOP with this and the Color image to produce something that will be aligned with the Depth image. (RealSense SDK for Windows only) segmentedcolor - Which outputs masked color image of the detected person in front of the camera. (RealSense SDK for Windows only) fisheye - (RealSense SDK for Windows only)",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Color Camera Resolution",
      "label": "Color Camera Resolution",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "colorres - Select the resolution of the video. Currently only usable for the Color image.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Max Depth",
      "label": "Max Depth",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "maxdepth - The depth value pixels with a value of 1 will be set to. Specified in Meters. Pixels with a depth larger than this will be clamped to 1 for fixed point texture output, or go above 1 for floating point output.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Mirror Image",
      "label": "Mirror Image",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "mirrorimage - Flip the image horizontally.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Default Tradeoff",
      "label": "Use Default Tradeoff",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "defaulttradeoff - Use the default Motion Range Tradeoff specified by the device.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Motion Range Tradeoff",
      "label": "Motion Range Tradeoff",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "tradeoff - Specifies the tradeoff between motion and range. Value is from 0 (short exposure, short range, and better motion) to 100 (long exposure and long range).",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Options CHOP",
      "label": "Options CHOP",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "optionschop - Channels specified in this  allow for setting all of the options that the RealSense camera supports. Channel names should be the same as the C enumeration, with the RS2_OPTION_ prefix removed, and all lowercase. E.g RS2_OPTION_ENABLE_AUTO_EXPOSURE can be set by using a channel named \"enable_auto_exposure\". A list of options can be found here.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Skeleton Tracking",
      "label": "Skeleton Tracking",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "skeltracking - When enabled, performs skeleton tracking using the Cubemos Skeleton Tracking API. The results can be fetched via the RealSense CHOP. A Cubemos license is required for usage. A trial license is available.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Default Paths",
      "label": "Use Default Paths",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "usedefaultpaths - When enabled, will search for the license and model files in the default location (LOCALAPPDATA). For the files to appear there the Cubemos SDK will need to be installed. If a specific license directory or model file is desired then this can be disabled.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "License Directory",
      "label": "License Directory",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "licensedir - Specify the directory with the license files (activation_key.json and cubemos_license.json).",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Skeleton Tracking Model File",
      "label": "Skeleton Tracking Model File",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "modelfile - Specify the model file (.cubemos)",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Output Resolution",
      "label": "Output Resolution",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Grow or shrink the input resolution to fit this resolution, while keeping the aspect ratio the same. limit - Limit the input resolution to be not larger than this resolution, while keeping the aspect ratio the same. custom - Directly control the width and height.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Grow or shrink the input resolution to fit this resolution, while keeping the aspect ratio the same. limit - Limit the input resolution to be not larger than this resolution, while keeping the aspect ratio the same. custom - Directly control the width and height.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.747Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Resolution",
      "label": "Resolution",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "W",
      "label": "W",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resolutionw - resolutionh -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Resolution Menu",
      "label": "Resolution Menu",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resmenu - A drop-down menu with some commonly used resolutions.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Global Res Multiplier",
      "label": "Use Global Res Multiplier",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Output Aspect",
      "label": "Output Aspect",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Aspect",
      "label": "Aspect",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Aspect1",
      "label": "Aspect1",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "aspect1 - aspect2 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Aspect Menu",
      "label": "Aspect Menu",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "armenu - A drop-down menu with some commonly used aspect ratios.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Input Smoothness",
      "label": "Input Smoothness",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Nearest Pixel",
      "label": "Nearest Pixel",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Fill Viewer",
      "label": "Fill Viewer",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.748Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Viewer Smoothness",
      "label": "Viewer Smoothness",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail. When the input is 32-bit float format, only nearest filtering will be used (regardless of what is selected).",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.749Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Nearest Pixel",
      "label": "Nearest Pixel",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail. When the input is 32-bit float format, only nearest filtering will be used (regardless of what is selected).",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.749Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Passes",
      "label": "Passes",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "npasses - Duplicates the operation of the  the specified number of times. For every pass after the first it takes the result of the previous pass and replaces the node's first input with the result of the previous pass. One exception to this is the GLSL TOP when using compute shaders, where the input will continue to be the connected 's image.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.749Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Channel Mask",
      "label": "Channel Mask",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.749Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Pixel Format",
      "label": "Pixel Format",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. Note that this does not apply an sRGB curve to the pixel values, it only stores them using an sRGB curve. This means more data is used for the darker values and less for the brighter values. When the values are read downstream they will be converted back to linear. For more information refer to sRGB. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.749Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. Note that this does not apply an sRGB curve to the pixel values, it only stores them using an sRGB curve. This means more data is used for the darker values and less for the brighter values. When the values are read downstream they will be converted back to linear. For more information refer to sRGB. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:51.749Z",
      "rawData": {},
      "sourceElement": null
    }
  ],
  "parameterGroups": {},
  "codeExamples": [],
  "pythonExamples": [],
  "expressions": [],
  "commonInputs": [],
  "commonOutputs": [],
  "relatedOperators": [],
  "workflowPatterns": [],
  "images": [],
  "videos": [],
  "assets": [],
  "keywords": [
    "realsense",
    "hardware:",
    "librealsense",
    "v2.50.0",
    "look",
    "like",
    "updated",
    "apple",
    "silicon,",
    "option",
    "builds."
  ],
  "tags": [
    "TOP",
    "TouchDesigner",
    "RealSense"
  ],
  "searchWeight": 1,
  "contentHash": "",
  "processingDate": "2025-08-08T00:37:51.750Z",
  "processingVersion": "1.0.0",
  "isValid": true,
  "validationErrors": []
}