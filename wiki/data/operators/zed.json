{
  "id": "zed",
  "name": "ZED",
  "displayName": "ZED",
  "category": "TOP",
  "subcategory": "Filters",
  "version": "",
  "lastUpdated": "2025-08-08T00:37:56.440Z",
  "sourceFile": "C:\\Program Files\\Derivative\\TouchDesigner\\Samples\\Learn\\OfflineHelp\\https.docs.derivative.ca\\ZED_TOP.htm",
  "url": "",
  "description": "OS: This operator is only supported under the Microsoft Windows operating system.",
  "summary": "OS: This operator is only supported under the Microsoft Windows operating system.",
  "details": "",
  "usage": "",
  "tips": [],
  "warnings": [],
  "parameters": [
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "From Derivative\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\t\nNOTE\n\nOS: This operator is only supported under the Microsoft Windows operating system.\n\n\nThe ZED  captures video from the ZED depth camera. \t\t\nNOTE: This  works with the Stereolabs ZED hardware. For more information and to know what ZED SDK to install refer to the ZED article.\nIt supports point clouds - getting the camera space positions of the color pixels, outputted as a 32-bit float RGB texture with XYZ in the RGB channels. It can be used in making point clouds renders as it is in the format for Geometry COMP instancing.\t\t\t\nSee also ZED CHOP and ZED SOP.\nzedTOP_Class\n\nContents\n \n \n \n \n \n \n \n\n\n\n\n\n  active - When set to 1 the  captures the image stream from the camera.\n\n\n\n  camera - Selects which ZED camera to use.\n\n\n\n  perspective -  - Choose between Left or Right camera.\n\n left - right -\n\n  image -  - Selects between the Color, Depth, Confidence, Disparity, Normals,  Cloud or Spatial Texture modes.\n\n color - Uses the RGB image from the camera. depth - Textures where the value of the pixel is the distance in meters from the camera. confidence - Gives the confidence/certainty of the depth map ranging from 0-1. disparity - Uses the disparity map from the camera. normals - Each RGB pixel of the texture gives the XYZ pixel normal in meters. pointcloud - The texture will be a 32-bit floating point texture where RGB pixel values are XYZ pixel values relative to the color camera, in meters. spatialtexture - Uses the texture extracted during spatial mapping by the ZED .\n\n  cameraresolution -  - Selects the resolution of the camera capture.\n\n 2208x1242 - 1920x1080 - 1280x720 - 672x376 -\n\n  camerafps - Sets the frame rate of the camera capture.\n\n\n\n  sensingmode -  - Selects betweem Standard and Fill mode.\n\n standard - Uses depth map that preserves edges and depth accuracy. interpolate - Interpolate between depth edges.\n\n  depthquality -  - Selects the depth computation mode of the camera.\n\n performance - Uses minimal resources for computation. quality - Uses high quality depth map requiring more resources. ultra - An even better quality depth map than high, but also requiring even more resources. neural - This use an AI model to refine the depth. On first use the model will need to be optimized for your , which will take serveral minutes. This only needs to occur once per machine.\n\n  mindepth - Sets the minimum depth in meters that will be computed.\n\n\n\n  maxdepth - Sets the maximum depth in meters.\n\n\n\n  toocloseval - For depth pixels that are too close to resolve, this pixel value will be output instead.\n\n\n\n  toofarval - For depth pixels that are too far to resolve, this pixel value will be output instead.\n\n\n\n  unknownval - For depth pixels whose depth can not be determined, output this value instead.\n\n\n\n  depthstabilization - Enables depth stabilization for the camera.\n\n\n\n  rerange - Enabling this will remap pixel values to 0-1.\n\n\n\n  referenceframe -  - Select between World and Camera reference frames for the  Cloud pixels.\n\n world - The pixel values are with reference to the initial position of the camera. camera - The pixel values are with relative to the current position of the camera.\n\n  resetcameratransform - Resets the camera position used for the reference frame above.\n\n\n\n  mirrorimage - Flips the image in the y-axis.\n\n\n\n\n  outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Grow or shrink the input resolution to fit this resolution, while keeping the aspect ratio the same. limit - Limit the input resolution to be not larger than this resolution, while keeping the aspect ratio the same. custom - Directly control the width and height.\n\n  resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -\n\n  resmenu - A drop-down menu with some commonly used resolutions.\n\n\n\n  resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.\n\n\n\n  outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.\n\n  aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -\n\n  armenu - A drop-down menu with some commonly used aspect ratios.\n\n\n\n  inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.\n\n  filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail. When the input is 32-bit float format, only nearest filtering will be used (regardless of what is selected).\n\n  npasses - Duplicates the operation of the  the specified number of times. For every pass after the first it takes the result of the previous pass and replaces the node's first input with the result of the previous pass. One exception to this is the GLSL TOP when using compute shaders, where the input will continue to be the connected 's image.\n\n\n\n  chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.\n\n\n\n  format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. Note that this does not apply an sRGB curve to the pixel values, it only stores them using an sRGB curve. This means more data is used for the darker values and less for the brighter values. When the values are read downstream they will be converted back to linear. For more information refer to sRGB. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.\n\n\n\nExtra Information for the ZED  can be accessed via an Info CHOP.\n\n\n - The physical vertical FOV of the camera, in degrees. - The physical horizontal FOV of the camera, in degrees.\n - Horizontal resolution of the  in pixels. - Vertical resolution of the  in pixels. - Horizontal aspect of the . - Vertical aspect of the . - Depth of 2D or 3D array if this  contains a 2D or 3D texture array. - Total amount of texture memory used by this .\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\nwikieditorwikieditorwikieditorwikieditorwikieditorwikieditorwikieditorwikieditorwikieditor2021.100002018.28070before 2018.28070\nTOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family that creates, composites and modifies images, and reads/writes images and movies to/from files and the network. TOPs run on the graphics card's GPU.\n\n\n\nEach SOP has a list of Points. Each point has an XYZ 3D position value plus other optional attributes. Each polygon Primitive is defined by a vertex list, which is list of point numbers.\n\n\n\nA Operator Family that reads, creates and modifies 3D points, polygons, lines, particles, surfaces, spheres and meatballs. Particles and point clouds are now done primarily on the GPU using TOPs.\n\n\n\nThe width and height of an image in pixels. Most TOPs, like the Movie File In TOP can set the image resolution. See Aspect Ratio for the width/height ratio of an image, taking into account non-square pixels.\n\n\n\nThe Frames-per-Second that TouchDesigner's Timeline runs at. Set with project.cookRate.\n\n\n\nThe Graphics Processing Unit. This is the high-speed, many-core processor of the graphics card/chip that takes geometry, images and data from the CPU and creates images and processed data.\n\n\n\nA Link. The grey dashed lines between nodes is a Reference or Link that indicates one operator is getting data from another operator from any Operator Family.\n\n\nThe grey dashed lines between nodes is a Reference (or Link). A Reference is (1) a Parameter Reference, a parameter in an OP that is a name or path to another operator, (2) a Node Reference, an expression in a parameter or DAT script that contains the name or path of another operator, (3) a DAT Cell Reference or (4) a CHOP Channel Reference.\n\n\nA Link or Reference is a dashed line between nodes that represent other data flowing between nodes. Examples are CHOP Exports, node Paths in parameters, and expressions in parameters referencing CHOP channels, DAT tables and other nodes. In contrast is a Wire that connects nodes in the same Operator Family.\n\n\n\nThe term \"Frame\" is a measurement of time used (1) in the Timeline, (2) as a time-unit in CHOPs, and (3) as a time unit in movie files that are read into TOPs and written out from TOPs. The frame rate is the frames per second (FPS).\n\n\n\nThe viewer of a node can be (1) the interior of a node (the Node Viewer), (2) a floating window (RMB->View... on node), or (3) a Pane that graphically shows the results of an operator.\n\n\n\nA CHOP outputs one or more channels, where a channel is simply a sequence of numbers (Samples), representing motion, audio, etc. Channels are passed between CHOPs in TouchDesigner networks. Channels can be Exported to Parameters.\n\n\n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=ZED_TOP&oldid=31720\"\n\t\tCategories: OP Help Common PagesTOPs",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.430Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "From Derivative\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\t\nNOTE\n\nOS: This operator is only supported under the Microsoft Windows operating system.\n\n\nThe ZED  captures video from the ZED depth camera. \t\t\nNOTE: This  works with the Stereolabs ZED hardware. For more information and to know what ZED SDK to install refer to the ZED article.\nIt supports point clouds - getting the camera space positions of the color pixels, outputted as a 32-bit float RGB texture with XYZ in the RGB channels. It can be used in making point clouds renders as it is in the format for Geometry COMP instancing.\t\t\t\nSee also ZED CHOP and ZED SOP.\nzedTOP_Class\n\nContents\n \n \n \n \n \n \n \n\n\n\n\n\n  active - When set to 1 the  captures the image stream from the camera.\n\n\n\n  camera - Selects which ZED camera to use.\n\n\n\n  perspective -  - Choose between Left or Right camera.\n\n left - right -\n\n  image -  - Selects between the Color, Depth, Confidence, Disparity, Normals,  Cloud or Spatial Texture modes.\n\n color - Uses the RGB image from the camera. depth - Textures where the value of the pixel is the distance in meters from the camera. confidence - Gives the confidence/certainty of the depth map ranging from 0-1. disparity - Uses the disparity map from the camera. normals - Each RGB pixel of the texture gives the XYZ pixel normal in meters. pointcloud - The texture will be a 32-bit floating point texture where RGB pixel values are XYZ pixel values relative to the color camera, in meters. spatialtexture - Uses the texture extracted during spatial mapping by the ZED .\n\n  cameraresolution -  - Selects the resolution of the camera capture.\n\n 2208x1242 - 1920x1080 - 1280x720 - 672x376 -\n\n  camerafps - Sets the frame rate of the camera capture.\n\n\n\n  sensingmode -  - Selects betweem Standard and Fill mode.\n\n standard - Uses depth map that preserves edges and depth accuracy. interpolate - Interpolate between depth edges.\n\n  depthquality -  - Selects the depth computation mode of the camera.\n\n performance - Uses minimal resources for computation. quality - Uses high quality depth map requiring more resources. ultra - An even better quality depth map than high, but also requiring even more resources. neural - This use an AI model to refine the depth. On first use the model will need to be optimized for your , which will take serveral minutes. This only needs to occur once per machine.\n\n  mindepth - Sets the minimum depth in meters that will be computed.\n\n\n\n  maxdepth - Sets the maximum depth in meters.\n\n\n\n  toocloseval - For depth pixels that are too close to resolve, this pixel value will be output instead.\n\n\n\n  toofarval - For depth pixels that are too far to resolve, this pixel value will be output instead.\n\n\n\n  unknownval - For depth pixels whose depth can not be determined, output this value instead.\n\n\n\n  depthstabilization - Enables depth stabilization for the camera.\n\n\n\n  rerange - Enabling this will remap pixel values to 0-1.\n\n\n\n  referenceframe -  - Select between World and Camera reference frames for the  Cloud pixels.\n\n world - The pixel values are with reference to the initial position of the camera. camera - The pixel values are with relative to the current position of the camera.\n\n  resetcameratransform - Resets the camera position used for the reference frame above.\n\n\n\n  mirrorimage - Flips the image in the y-axis.\n\n\n\n\n  outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Grow or shrink the input resolution to fit this resolution, while keeping the aspect ratio the same. limit - Limit the input resolution to be not larger than this resolution, while keeping the aspect ratio the same. custom - Directly control the width and height.\n\n  resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -\n\n  resmenu - A drop-down menu with some commonly used resolutions.\n\n\n\n  resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.\n\n\n\n  outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.\n\n  aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -\n\n  armenu - A drop-down menu with some commonly used aspect ratios.\n\n\n\n  inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.\n\n  filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail. When the input is 32-bit float format, only nearest filtering will be used (regardless of what is selected).\n\n  npasses - Duplicates the operation of the  the specified number of times. For every pass after the first it takes the result of the previous pass and replaces the node's first input with the result of the previous pass. One exception to this is the GLSL TOP when using compute shaders, where the input will continue to be the connected 's image.\n\n\n\n  chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.\n\n\n\n  format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. Note that this does not apply an sRGB curve to the pixel values, it only stores them using an sRGB curve. This means more data is used for the darker values and less for the brighter values. When the values are read downstream they will be converted back to linear. For more information refer to sRGB. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.\n\n\n\nExtra Information for the ZED  can be accessed via an Info CHOP.\n\n\n - The physical vertical FOV of the camera, in degrees. - The physical horizontal FOV of the camera, in degrees.\n - Horizontal resolution of the  in pixels. - Vertical resolution of the  in pixels. - Horizontal aspect of the . - Vertical aspect of the . - Depth of 2D or 3D array if this  contains a 2D or 3D texture array. - Total amount of texture memory used by this .\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\nwikieditorwikieditorwikieditorwikieditorwikieditorwikieditorwikieditorwikieditorwikieditor2021.100002018.28070before 2018.28070\nTOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family that creates, composites and modifies images, and reads/writes images and movies to/from files and the network. TOPs run on the graphics card's GPU.\n\n\n\nEach SOP has a list of Points. Each point has an XYZ 3D position value plus other optional attributes. Each polygon Primitive is defined by a vertex list, which is list of point numbers.\n\n\n\nA Operator Family that reads, creates and modifies 3D points, polygons, lines, particles, surfaces, spheres and meatballs. Particles and point clouds are now done primarily on the GPU using TOPs.\n\n\n\nThe width and height of an image in pixels. Most TOPs, like the Movie File In TOP can set the image resolution. See Aspect Ratio for the width/height ratio of an image, taking into account non-square pixels.\n\n\n\nThe Frames-per-Second that TouchDesigner's Timeline runs at. Set with project.cookRate.\n\n\n\nThe Graphics Processing Unit. This is the high-speed, many-core processor of the graphics card/chip that takes geometry, images and data from the CPU and creates images and processed data.\n\n\n\nA Link. The grey dashed lines between nodes is a Reference or Link that indicates one operator is getting data from another operator from any Operator Family.\n\n\nThe grey dashed lines between nodes is a Reference (or Link). A Reference is (1) a Parameter Reference, a parameter in an OP that is a name or path to another operator, (2) a Node Reference, an expression in a parameter or DAT script that contains the name or path of another operator, (3) a DAT Cell Reference or (4) a CHOP Channel Reference.\n\n\nA Link or Reference is a dashed line between nodes that represent other data flowing between nodes. Examples are CHOP Exports, node Paths in parameters, and expressions in parameters referencing CHOP channels, DAT tables and other nodes. In contrast is a Wire that connects nodes in the same Operator Family.\n\n\n\nThe term \"Frame\" is a measurement of time used (1) in the Timeline, (2) as a time-unit in CHOPs, and (3) as a time unit in movie files that are read into TOPs and written out from TOPs. The frame rate is the frames per second (FPS).\n\n\n\nThe viewer of a node can be (1) the interior of a node (the Node Viewer), (2) a floating window (RMB->View... on node), or (3) a Pane that graphically shows the results of an operator.\n\n\n\nA CHOP outputs one or more channels, where a channel is simply a sequence of numbers (Samples), representing motion, audio, etc. Channels are passed between CHOPs in TouchDesigner networks. Channels can be Exported to Parameters.\n\n\n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=ZED_TOP&oldid=31720\"\n\t\tCategories: OP Help Common PagesTOPs",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.433Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "NOTE\n\nOS: This operator is only supported under the Microsoft Windows operating system.\n\n\nThe ZED  captures video from the ZED depth camera. \t\t\nNOTE: This  works with the Stereolabs ZED hardware. For more information and to know what ZED SDK to install refer to the ZED article.\nIt supports point clouds - getting the camera space positions of the color pixels, outputted as a 32-bit float RGB texture with XYZ in the RGB channels. It can be used in making point clouds renders as it is in the format for Geometry COMP instancing.\t\t\t\nSee also ZED CHOP and ZED SOP.\nzedTOP_Class\n\nContents\n \n \n \n \n \n \n \n\n\n\n\n\n  active - When set to 1 the  captures the image stream from the camera.\n\n\n\n  camera - Selects which ZED camera to use.\n\n\n\n  perspective -  - Choose between Left or Right camera.\n\n left - right -\n\n  image -  - Selects between the Color, Depth, Confidence, Disparity, Normals,  Cloud or Spatial Texture modes.\n\n color - Uses the RGB image from the camera. depth - Textures where the value of the pixel is the distance in meters from the camera. confidence - Gives the confidence/certainty of the depth map ranging from 0-1. disparity - Uses the disparity map from the camera. normals - Each RGB pixel of the texture gives the XYZ pixel normal in meters. pointcloud - The texture will be a 32-bit floating point texture where RGB pixel values are XYZ pixel values relative to the color camera, in meters. spatialtexture - Uses the texture extracted during spatial mapping by the ZED .\n\n  cameraresolution -  - Selects the resolution of the camera capture.\n\n 2208x1242 - 1920x1080 - 1280x720 - 672x376 -\n\n  camerafps - Sets the frame rate of the camera capture.\n\n\n\n  sensingmode -  - Selects betweem Standard and Fill mode.\n\n standard - Uses depth map that preserves edges and depth accuracy. interpolate - Interpolate between depth edges.\n\n  depthquality -  - Selects the depth computation mode of the camera.\n\n performance - Uses minimal resources for computation. quality - Uses high quality depth map requiring more resources. ultra - An even better quality depth map than high, but also requiring even more resources. neural - This use an AI model to refine the depth. On first use the model will need to be optimized for your , which will take serveral minutes. This only needs to occur once per machine.\n\n  mindepth - Sets the minimum depth in meters that will be computed.\n\n\n\n  maxdepth - Sets the maximum depth in meters.\n\n\n\n  toocloseval - For depth pixels that are too close to resolve, this pixel value will be output instead.\n\n\n\n  toofarval - For depth pixels that are too far to resolve, this pixel value will be output instead.\n\n\n\n  unknownval - For depth pixels whose depth can not be determined, output this value instead.\n\n\n\n  depthstabilization - Enables depth stabilization for the camera.\n\n\n\n  rerange - Enabling this will remap pixel values to 0-1.\n\n\n\n  referenceframe -  - Select between World and Camera reference frames for the  Cloud pixels.\n\n world - The pixel values are with reference to the initial position of the camera. camera - The pixel values are with relative to the current position of the camera.\n\n  resetcameratransform - Resets the camera position used for the reference frame above.\n\n\n\n  mirrorimage - Flips the image in the y-axis.\n\n\n\n\n  outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Grow or shrink the input resolution to fit this resolution, while keeping the aspect ratio the same. limit - Limit the input resolution to be not larger than this resolution, while keeping the aspect ratio the same. custom - Directly control the width and height.\n\n  resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -\n\n  resmenu - A drop-down menu with some commonly used resolutions.\n\n\n\n  resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.\n\n\n\n  outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.\n\n  aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -\n\n  armenu - A drop-down menu with some commonly used aspect ratios.\n\n\n\n  inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.\n\n  fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.\n\n  filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail. When the input is 32-bit float format, only nearest filtering will be used (regardless of what is selected).\n\n  npasses - Duplicates the operation of the  the specified number of times. For every pass after the first it takes the result of the previous pass and replaces the node's first input with the result of the previous pass. One exception to this is the GLSL TOP when using compute shaders, where the input will continue to be the connected 's image.\n\n\n\n  chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.\n\n\n\n  format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. Note that this does not apply an sRGB curve to the pixel values, it only stores them using an sRGB curve. This means more data is used for the darker values and less for the brighter values. When the values are read downstream they will be converted back to linear. For more information refer to sRGB. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.\n\n\n\nExtra Information for the ZED  can be accessed via an Info CHOP.\n\n\n - The physical vertical FOV of the camera, in degrees. - The physical horizontal FOV of the camera, in degrees.\n - Horizontal resolution of the  in pixels. - Vertical resolution of the  in pixels. - Horizontal aspect of the . - Vertical aspect of the . - Depth of 2D or 3D array if this  contains a 2D or 3D texture array. - Total amount of texture memory used by this .\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\nwikieditorwikieditorwikieditorwikieditorwikieditorwikieditorwikieditorwikieditorwikieditor2021.100002018.28070before 2018.28070\nTOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family that creates, composites and modifies images, and reads/writes images and movies to/from files and the network. TOPs run on the graphics card's GPU.\n\n\n\nEach SOP has a list of Points. Each point has an XYZ 3D position value plus other optional attributes. Each polygon Primitive is defined by a vertex list, which is list of point numbers.\n\n\n\nA Operator Family that reads, creates and modifies 3D points, polygons, lines, particles, surfaces, spheres and meatballs. Particles and point clouds are now done primarily on the GPU using TOPs.\n\n\n\nThe width and height of an image in pixels. Most TOPs, like the Movie File In TOP can set the image resolution. See Aspect Ratio for the width/height ratio of an image, taking into account non-square pixels.\n\n\n\nThe Frames-per-Second that TouchDesigner's Timeline runs at. Set with project.cookRate.\n\n\n\nThe Graphics Processing Unit. This is the high-speed, many-core processor of the graphics card/chip that takes geometry, images and data from the CPU and creates images and processed data.\n\n\n\nA Link. The grey dashed lines between nodes is a Reference or Link that indicates one operator is getting data from another operator from any Operator Family.\n\n\nThe grey dashed lines between nodes is a Reference (or Link). A Reference is (1) a Parameter Reference, a parameter in an OP that is a name or path to another operator, (2) a Node Reference, an expression in a parameter or DAT script that contains the name or path of another operator, (3) a DAT Cell Reference or (4) a CHOP Channel Reference.\n\n\nA Link or Reference is a dashed line between nodes that represent other data flowing between nodes. Examples are CHOP Exports, node Paths in parameters, and expressions in parameters referencing CHOP channels, DAT tables and other nodes. In contrast is a Wire that connects nodes in the same Operator Family.\n\n\n\nThe term \"Frame\" is a measurement of time used (1) in the Timeline, (2) as a time-unit in CHOPs, and (3) as a time unit in movie files that are read into TOPs and written out from TOPs. The frame rate is the frames per second (FPS).\n\n\n\nThe viewer of a node can be (1) the interior of a node (the Node Viewer), (2) a floating window (RMB->View... on node), or (3) a Pane that graphically shows the results of an operator.\n\n\n\nA CHOP outputs one or more channels, where a channel is simply a sequence of numbers (Samples), representing motion, audio, etc. Channels are passed between CHOPs in TouchDesigner networks. Channels can be Exported to Parameters.\n\n\n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=ZED_TOP&oldid=31720\"",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Active",
      "label": "Active",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "active - When set to 1 the  captures the image stream from the camera.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Camera",
      "label": "Camera",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "camera - Selects which ZED camera to use.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Perspective",
      "label": "Perspective",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "perspective -  - Choose between Left or Right camera.\n\n left - right -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Left",
      "label": "Left",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "left - right -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Image",
      "label": "Image",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "image -  - Selects between the Color, Depth, Confidence, Disparity, Normals,  Cloud or Spatial Texture modes.\n\n color - Uses the RGB image from the camera. depth - Textures where the value of the pixel is the distance in meters from the camera. confidence - Gives the confidence/certainty of the depth map ranging from 0-1. disparity - Uses the disparity map from the camera. normals - Each RGB pixel of the texture gives the XYZ pixel normal in meters. pointcloud - The texture will be a 32-bit floating point texture where RGB pixel values are XYZ pixel values relative to the color camera, in meters. spatialtexture - Uses the texture extracted during spatial mapping by the ZED .",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Color",
      "label": "Color",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "color - Uses the RGB image from the camera. depth - Textures where the value of the pixel is the distance in meters from the camera. confidence - Gives the confidence/certainty of the depth map ranging from 0-1. disparity - Uses the disparity map from the camera. normals - Each RGB pixel of the texture gives the XYZ pixel normal in meters. pointcloud - The texture will be a 32-bit floating point texture where RGB pixel values are XYZ pixel values relative to the color camera, in meters. spatialtexture - Uses the texture extracted during spatial mapping by the ZED .",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Camera Resolution",
      "label": "Camera Resolution",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "cameraresolution -  - Selects the resolution of the camera capture.\n\n 2208x1242 - 1920x1080 - 1280x720 - 672x376 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "2208 x 1242",
      "label": "2208 x 1242",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "2208x1242 - 1920x1080 - 1280x720 - 672x376 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Camera FPS",
      "label": "Camera FPS",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "camerafps - Sets the frame rate of the camera capture.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Sensing Mode",
      "label": "Sensing Mode",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "sensingmode -  - Selects betweem Standard and Fill mode.\n\n standard - Uses depth map that preserves edges and depth accuracy. interpolate - Interpolate between depth edges.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Standard",
      "label": "Standard",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "standard - Uses depth map that preserves edges and depth accuracy. interpolate - Interpolate between depth edges.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Depth Quality",
      "label": "Depth Quality",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "depthquality -  - Selects the depth computation mode of the camera.\n\n performance - Uses minimal resources for computation. quality - Uses high quality depth map requiring more resources. ultra - An even better quality depth map than high, but also requiring even more resources. neural - This use an AI model to refine the depth. On first use the model will need to be optimized for your , which will take serveral minutes. This only needs to occur once per machine.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.436Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Performance",
      "label": "Performance",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "performance - Uses minimal resources for computation. quality - Uses high quality depth map requiring more resources. ultra - An even better quality depth map than high, but also requiring even more resources. neural - This use an AI model to refine the depth. On first use the model will need to be optimized for your , which will take serveral minutes. This only needs to occur once per machine.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Minimum Depth",
      "label": "Minimum Depth",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "mindepth - Sets the minimum depth in meters that will be computed.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Maximum Depth",
      "label": "Maximum Depth",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "maxdepth - Sets the maximum depth in meters.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Too Close Value",
      "label": "Too Close Value",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "toocloseval - For depth pixels that are too close to resolve, this pixel value will be output instead.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Too Far Value",
      "label": "Too Far Value",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "toofarval - For depth pixels that are too far to resolve, this pixel value will be output instead.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Unknown Value",
      "label": "Unknown Value",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "unknownval - For depth pixels whose depth can not be determined, output this value instead.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Depth Stabilization",
      "label": "Depth Stabilization",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "depthstabilization - Enables depth stabilization for the camera.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Rerange",
      "label": "Rerange",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "rerange - Enabling this will remap pixel values to 0-1.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Reference Frame",
      "label": "Reference Frame",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "referenceframe -  - Select between World and Camera reference frames for the  Cloud pixels.\n\n world - The pixel values are with reference to the initial position of the camera. camera - The pixel values are with relative to the current position of the camera.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "World",
      "label": "World",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "world - The pixel values are with reference to the initial position of the camera. camera - The pixel values are with relative to the current position of the camera.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Camera Transform",
      "label": "Camera Transform",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resetcameratransform - Resets the camera position used for the reference frame above.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Mirror Image",
      "label": "Mirror Image",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "mirrorimage - Flips the image in the y-axis.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Output Resolution",
      "label": "Output Resolution",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "outputresolution -  - quickly change the resolution of the 's data.\n\n useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Grow or shrink the input resolution to fit this resolution, while keeping the aspect ratio the same. limit - Limit the input resolution to be not larger than this resolution, while keeping the aspect ratio the same. custom - Directly control the width and height.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the input's resolution. eighth - Multiply the input's resolution by that amount. quarter - Multiply the input's resolution by that amount. half - Multiply the input's resolution by that amount. 2x - Multiply the input's resolution by that amount. 4x - Multiply the input's resolution by that amount. 8x - Multiply the input's resolution by that amount. fit - Grow or shrink the input resolution to fit this resolution, while keeping the aspect ratio the same. limit - Limit the input resolution to be not larger than this resolution, while keeping the aspect ratio the same. custom - Directly control the width and height.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Resolution",
      "label": "Resolution",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resolution -  - Enabled only when the  parameter is set to Custom . Some Generators like Constant and Ramp do not use inputs and only use this field to determine their size. The drop down menu on the right provides some commonly used resolutions.\n\n resolutionw - resolutionh -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "W",
      "label": "W",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resolutionw - resolutionh -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.437Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Resolution Menu",
      "label": "Resolution Menu",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resmenu - A drop-down menu with some commonly used resolutions.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Global Res Multiplier",
      "label": "Use Global Res Multiplier",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "resmult - Uses the Global  Multiplier found in Edit>Preferences>TOPs. This multiplies all the TOPs resolutions by the set amount. This is handy when working on computers with different hardware specifications. If a project is designed on a desktop workstation with lots of graphics memory, a user on a laptop with only 64MB VRAM can set the Global  Multiplier to a value of half or quarter so it runs at an acceptable speed. By checking this checkbox on, this  is affected by the global multiplier.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Output Aspect",
      "label": "Output Aspect",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "outputaspect -  - Sets the image aspect ratio allowing any textures to be viewed in any size. Watch for unexpected results when compositing TOPs with different aspect ratios. (You can define images with non-square pixels using xres, yres, aspectx, aspecty where xres/yres != aspectx/aspecty.)\n\n useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the input's aspect ratio. resolution - Uses the aspect of the image's defined resolution (ie 512x256 would be 2:1), whereby each pixel is square. custom - Lets you explicitly define a custom aspect ratio in the Aspect parameter below.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Aspect",
      "label": "Aspect",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "aspect -  - Use when Output Aspect parameter is set to Custom Aspect.\n\n aspect1 - aspect2 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Aspect1",
      "label": "Aspect1",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "aspect1 - aspect2 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Aspect Menu",
      "label": "Aspect Menu",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "armenu - A drop-down menu with some commonly used aspect ratios.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Input Smoothness",
      "label": "Input Smoothness",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "inputfiltertype -  - This controls pixel filtering on the input image of the .\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Nearest Pixel",
      "label": "Nearest Pixel",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. This is how you get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Fill Viewer",
      "label": "Fill Viewer",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "fillmode -  - Determine how the  image is displayed in the viewer.\nNOTE:To get an understanding of how TOPs work with images, you will want to set this to Native  as you lay down TOPs when starting out. This will let you see what is actually happening without any automatic viewer resizing.\n\n\n useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the same Fill Viewer settings as it's input. fill - Stretches the image to fit the edges of the viewer. width - Stretches image to fit viewer horizontally. height - Stretches image to fit viewer vertically. best - Stretches or squashes image so no part of image is cropped. outside - Stretches or squashes image so image fills viewer while constraining it's proportions. This often leads to part of image getting cropped by viewer. nativeres - Displays the native resolution of the image in the viewer.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Viewer Smoothness",
      "label": "Viewer Smoothness",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "filtertype -  - This controls pixel filtering in the viewers.\n\n nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail. When the input is 32-bit float format, only nearest filtering will be used (regardless of what is selected).",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Nearest Pixel",
      "label": "Nearest Pixel",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "nearest - Uses nearest pixel or accurate image representation. Images will look jaggy when viewing at any zoom level other than Native . linear - Uses linear filtering between pixels. Use this to get  images in viewers to look good at various zoom levels, especially useful when using any Fill Viewer setting other than Native . mipmap - Uses  mipmap filtering when scaling images. This can be used to reduce artifacts and sparkling in moving/scaling images that have lots of detail. When the input is 32-bit float format, only nearest filtering will be used (regardless of what is selected).",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Passes",
      "label": "Passes",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "npasses - Duplicates the operation of the  the specified number of times. For every pass after the first it takes the result of the previous pass and replaces the node's first input with the result of the previous pass. One exception to this is the GLSL TOP when using compute shaders, where the input will continue to be the connected 's image.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Channel Mask",
      "label": "Channel Mask",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "chanmask - Allows you to choose which channels (R, G, B, or A) the  will operate on. All channels are selected by default.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.438Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Pixel Format",
      "label": "Pixel Format",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "format -  - Format used to store data for each channel in the image (ie. R, G, B, and A). Refer to Pixel Formats for more information.\n\n useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. Note that this does not apply an sRGB curve to the pixel values, it only stores them using an sRGB curve. This means more data is used for the darker values and less for the brighter values. When the values are read downstream they will be converted back to linear. For more information refer to sRGB. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.439Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Use Input",
      "label": "Use Input",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "useinput - Uses the input's pixel format. rgba8fixed - Uses 8-bit integer values for each channel. srgba8fixed - Uses 8-bit integer values for each channel and stores color in sRGB colorspace. Note that this does not apply an sRGB curve to the pixel values, it only stores them using an sRGB curve. This means more data is used for the darker values and less for the brighter values. When the values are read downstream they will be converted back to linear. For more information refer to sRGB. rgba16float - Uses 16-bits per color channel, 64-bits per pixel. rgba32float - Uses 32-bits per color channel, 128-bits per pixels. rgb10a2fixed - Uses 10-bits per color channel and 2-bits for alpha, 32-bits total per pixel. rgba16fixed - Uses 16-bits per color channel, 64-bits total per pixel. rgba11float - A RGB floating point format that has 11 bits for the Red and Green channels, and 10-bits for the Blue , 32-bits total per pixel (therefore the same memory usage as 8-bit RGBA). The Alpha channel in this format will always be 1. Values can go above one, but can't be negative. ie. the range is [0, infinite). rgb16float - rgb32float - mono8fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 8-bits per pixel. mono16fixed - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono16float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 16-bits per pixel. mono32float - Single channel, where RGB will all have the same value, and Alpha will be 1.0. 32-bits per pixel. rg8fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 8-bits per channel, 16-bits total per pixel. rg16fixed - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg16float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 16-bits per channel, 32-bits total per pixel. rg32float - A 2 channel format, R and G have values, while B is 0 always and Alpha is 1.0. 32-bits per channel, 64-bits total per pixel. a8fixed - An Alpha only format that has 8-bits per channel, 8-bits per pixel. a16fixed - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a16float - An Alpha only format that has 16-bits per channel, 16-bits per pixel. a32float - An Alpha only format that has 32-bits per channel, 32-bits per pixel. monoalpha8fixed - A 2 channel format, one value for RGB and one value for Alpha. 8-bits per channel, 16-bits per pixel. monoalpha16fixed - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha16float - A 2 channel format, one value for RGB and one value for Alpha. 16-bits per channel, 32-bits per pixel. monoalpha32float - A 2 channel format, one value for RGB and one value for Alpha. 32-bits per channel, 64-bits per pixel.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-08T00:37:56.439Z",
      "rawData": {},
      "sourceElement": null
    }
  ],
  "parameterGroups": {},
  "codeExamples": [],
  "pythonExamples": [],
  "expressions": [],
  "commonInputs": [],
  "commonOutputs": [],
  "relatedOperators": [],
  "workflowPatterns": [],
  "images": [],
  "videos": [],
  "assets": [],
  "keywords": [
    "zed",
    "only",
    "supported",
    "under",
    "microsoft",
    "windows",
    "operating",
    "system."
  ],
  "tags": [
    "TOP",
    "TouchDesigner",
    "ZED"
  ],
  "searchWeight": 1,
  "contentHash": "",
  "processingDate": "2025-08-08T00:37:56.440Z",
  "processingVersion": "1.0.0",
  "isValid": true,
  "validationErrors": []
}