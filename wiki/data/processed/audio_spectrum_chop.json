{
  "id": "audio_spectrum_chop",
  "name": "Audio Spectrum CHOP",
  "displayName": "Audio Spectrum CHOP",
  "category": "CHOP",
  "subcategory": "Audio",
  "version": "",
  "lastUpdated": "2025-08-07T07:49:57.127Z",
  "sourceFile": "C:\\Program Files\\Derivative\\TouchDesigner\\Samples\\Learn\\OfflineHelp\\https.docs.derivative.ca\\Audio_Spectrum_CHOP.htm",
  "url": "",
  "description": "The Audio Spectrum CHOP calculates and displays the frequency spectrum of the input channels.",
  "summary": "The Audio Spectrum CHOP calculates and displays the frequency spectrum of the input channels.",
  "details": "",
  "usage": "",
  "tips": [],
  "warnings": [],
  "parameters": [
    {
      "id": null,
      "name": "Mode",
      "label": "Mode",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "From Derivative\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\t\nThe Audio Spectrum  calculates and displays the frequency spectrum of the input channels. \t\t\nIn the default Visualization Mode the  is set to display the spectrum in a more understandable way by emphasizing the higher frequency levels and the lower frequency ranges.\t\t\t\nIn another Mode, the Time to Magnitude and Phase mode, the audio can be converted to the frequency spectrum domain, manipulated and then converted back to get a filtered audio signal. When converting a signal to its spectrum, two channels are created from the one containing the audio signal. One channel contains the magnitude of the frequency components, and the other contains the phase. The channels are named, for example chan1_m and chan1_p where _m and _p are the suffixes for the magnitude and phase channels.\t\t\t\nTip:  You can reduce cook time if you decrease the FFT Size from its default 8192 samples. The fastest form of this  is by setting the Output Length parameter to \"Output Length Manually\". For example set the output buffer size to 2048 samples and the FFT Size to 2048. Each time it cooks, the  is looking at the latest 2028 samples (at 44.1 KHz that amounts to the 50 msec, or 3 frames), which is plenty. Note the default form of the  gives you 22,000 samples: 1 Hz to 22,050 Hz in steps of 1 Hz (when set to Frequency vs Logarithmic scaling), designed for clear interpretation: sample 1000 is the level of audio at 1000 Hz.\t\nTip:  To find the exact frequency of a wave entering the Audio Spectrum , look at the Info pop-up for that node (MMB on the node). It says:  Set \"Frequency <-> Logarithmic Scaling\" to 0, then multiply any sample to xxxx to get the Frequency at that sample.  xxxx depends on the sample rates etc and isn't a constant.\nSee Audio Filter CHOP, Audio Para EQ CHOP, Audio Band EQ CHOP, Audio Oscillator CHOP set to White Noise.\naudiospectrumCHOP_Class\n\nContents\n \n \n \n \n \n \n \n \n \n\n\n\n\n\n  mode -  - Select which mode to use, modes described below.\n\n visual - Show the spectrum in a way that more useful, with (by default) high frequencies boosted in level, and lower frequencies boosted in horizontal range. timetoraw - Calculate the frequency spectrum assuming input is a signal. rawtotime - Reconstructs a signal assuming input is a frequency spectrum similar to that coming from and Audio Spectum  set to the above option.\n\t\t\n  fftsize -  - Converting to frequency needs a power-of-2 number of samples, like 512, 1024, 2048. (FFT means Fast Fourier Transform.) The more samples, the more accurate the spectrum but the more it doesn't represent the most recent sound. Whatever the size, the  uses the most recent samples. Knowing that audio at 44100 samples per second with a timeline frame rate of 60 frames per second gives 735 samples per frame, if the  cooks 1 frame later and the FFT size is 1024, then it will re-use 1024-735 = 289 samples, which is good as there's a little overlap. However if it cooks 2 frames later, it will miss using 446 frames since it will have advanced 735*2=1470 samples and it will only use 1024 of them.\n\n 64 - 128 - 256 - 512 - 1024 - 2048 - 4096 - 8192 - 16384 -\n\t\t\n  frequencylog - Logarithmic (=1) is more tangible for human hearing. Each octave is represented with the same number of samples, so low frequencies are more readable. Frequency (=0) shows one sample for a fixed number of Hz, which is what the raw FFT gives, but most of the upper samples are uninteresting. Your ears hear ranges of octaves better.  IMPORTANT NOTE: If Mode is set to Visualization and this parameter is set to 0, the output data is interpreted more simply: 1 sample per Hz. Set the  viewer Units to Samples (via RMB on  graph) and the level you see at sample 5000 is the level at 5 KHz.\n\n\n\t\t\n  highfreqboost - When 0, the levels are not changed. When greater than 1, the levels are boosted, mostly at the high frequencies. High Frequency Boost can be over-driven past 1.\n\n\n\t\t\n  outputmenu -  - The method how output length will be determined.\n\n matchtofrequency - setmanually -\n\t\t\n  outlength - Number of Samples desired in output. The fewer the samples, the less the frequency resolution.\n\n\n\n\n\n  timeslice - Turning this on forces the channels to be \"Time Sliced\".  A  is the time between the last cook frame and the current cook frame.\n\n\n\n  scope - To determine which channels get affected, some CHOPs use a  string on the Common page. See Pattern Matching.\n\n\n\n  srselect -  - Handle cases where multiple input CHOPs' sample rates are different. When Resampling occurs, the curves are interpolated according to the Interpolation Method Option, or \"Linear\" if the Interpolate Options are not available.\n\n first - Use rate of first input to resample others. max - Resample to the highest sample rate. min - Resample to the lowest sample rate. err - Doesn't accept conflicting sample rates.\n\n  exportmethod -  - This will determine how to connect the  channel to the parameter. Refer to the Export article for more information.\n\n datindex - Uses the docked  table and references the channel via the index of the channel in the . datname - Uses the docked  table and references the channel via the name of the channel in the . autoname - The channel is the full destination of where to export to, such has geo1/transform1:tx.\n\n  autoexportroot - This path points to the root node where all of the paths that exporting by Channel Name is : are relative to.\n\n\n\n  exporttable - The  used to hold the export information when using the  Table  Methods (See above).\n\n\n\n\n\nA reasonable scenario (in terms of CPU usage) is an FFT size of 2048. You get good definition with the spectrum, and also enough padding to (almost) deal with two dropped frames.\nAn Info CHOP can be attached and the channel hz_per_sample can be viewed. Applicable only of the Frequency axis is set to Linear.\nWith it set to output to normal FFT, to determine the frequency that a given sample represents, use the formula:\nIn order to convert back to a signal, both channels are required. The suffixes should be the same as those used in the previous Audio Spectrum .\n\n\n -\n\nExtra Information for the Audio Spectrum  can be accessed via an Info CHOP.\n\n\n -\n - Start of the  interval in samples. - Number of samples in the . - The samplerate of the channels in frames per second. - Number of channels in the . - 1 if  is  enabled, 0 otherwise. - A count of how often the export connections have been updated.\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\n2022.241402021.100002018.28070before 2018.28070\nCHOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\nA Time Slice is the time from the last cook frame to the current cook frame. In CHOPs it is the set of short channels that contain the CHOP channels' samples between the last and the current cook frame.\n\n\n\nA parameter in most CHOPs that restricts which channels of that CHOP will be affected. Normally all channels of a CHOP are affected by the operator. TOPs have Channel Mask, a similar feature.\n\n\n\nsamples-per-second of a CHOP. Each CHOP in your network has a sample rate. In contrast, the overall timeline has a Frame Rate, which is the number of frames to cook and display per second, generally your monitor display frequency, default 60.\n\n\n\nExporting is the connection of CHOP channels to parameters of operators. The output of each exporting CHOP is one or more channels, active only while the CHOP Viewer is on. The current value of a channel can be exported to a parameter of any operator, overriding that parameter's value. See Parameter.\n\n\n\nAn Operator Family that manipulates text strings: multi-line text or tables. Multi-line text is often a python Script or GLSL Shader, but can be any multi-line text. Tables are rows and columns of cells, each containing a text string.\n\n\n\nThe location of an operator within the TouchDesigner environment, for example, /geo1/circle1, a node called circle1 in a component called geo1. The path / is called Root. This path is displayed at the top of every Pane, showing which Component's network you are currently in. To refer instead to a filesystem folder, directory, disk file or http: address, see Folder.\n\n\n\nEvery operator in TouchDesigner has a set of control Parameters that can be integer or floating point numbers, menus, binary toggles, text strings or operator paths, which determine the output of the operator.\n\n\n\nTouchDesigner is a hierarchy of components. \"root\" is the top-most network in the hierarchy. The Network Path or Path for root is simply /. A typical path is /project1/moviein1.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=Audio_Spectrum_CHOP&oldid=24443\"\n\t\tCategory: CHOPs",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.121Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Mode",
      "label": "Mode",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "From Derivative\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\t\nThe Audio Spectrum  calculates and displays the frequency spectrum of the input channels. \t\t\nIn the default Visualization Mode the  is set to display the spectrum in a more understandable way by emphasizing the higher frequency levels and the lower frequency ranges.\t\t\t\nIn another Mode, the Time to Magnitude and Phase mode, the audio can be converted to the frequency spectrum domain, manipulated and then converted back to get a filtered audio signal. When converting a signal to its spectrum, two channels are created from the one containing the audio signal. One channel contains the magnitude of the frequency components, and the other contains the phase. The channels are named, for example chan1_m and chan1_p where _m and _p are the suffixes for the magnitude and phase channels.\t\t\t\nTip:  You can reduce cook time if you decrease the FFT Size from its default 8192 samples. The fastest form of this  is by setting the Output Length parameter to \"Output Length Manually\". For example set the output buffer size to 2048 samples and the FFT Size to 2048. Each time it cooks, the  is looking at the latest 2028 samples (at 44.1 KHz that amounts to the 50 msec, or 3 frames), which is plenty. Note the default form of the  gives you 22,000 samples: 1 Hz to 22,050 Hz in steps of 1 Hz (when set to Frequency vs Logarithmic scaling), designed for clear interpretation: sample 1000 is the level of audio at 1000 Hz.\t\nTip:  To find the exact frequency of a wave entering the Audio Spectrum , look at the Info pop-up for that node (MMB on the node). It says:  Set \"Frequency <-> Logarithmic Scaling\" to 0, then multiply any sample to xxxx to get the Frequency at that sample.  xxxx depends on the sample rates etc and isn't a constant.\nSee Audio Filter CHOP, Audio Para EQ CHOP, Audio Band EQ CHOP, Audio Oscillator CHOP set to White Noise.\naudiospectrumCHOP_Class\n\nContents\n \n \n \n \n \n \n \n \n \n\n\n\n\n\n  mode -  - Select which mode to use, modes described below.\n\n visual - Show the spectrum in a way that more useful, with (by default) high frequencies boosted in level, and lower frequencies boosted in horizontal range. timetoraw - Calculate the frequency spectrum assuming input is a signal. rawtotime - Reconstructs a signal assuming input is a frequency spectrum similar to that coming from and Audio Spectum  set to the above option.\n\t\t\n  fftsize -  - Converting to frequency needs a power-of-2 number of samples, like 512, 1024, 2048. (FFT means Fast Fourier Transform.) The more samples, the more accurate the spectrum but the more it doesn't represent the most recent sound. Whatever the size, the  uses the most recent samples. Knowing that audio at 44100 samples per second with a timeline frame rate of 60 frames per second gives 735 samples per frame, if the  cooks 1 frame later and the FFT size is 1024, then it will re-use 1024-735 = 289 samples, which is good as there's a little overlap. However if it cooks 2 frames later, it will miss using 446 frames since it will have advanced 735*2=1470 samples and it will only use 1024 of them.\n\n 64 - 128 - 256 - 512 - 1024 - 2048 - 4096 - 8192 - 16384 -\n\t\t\n  frequencylog - Logarithmic (=1) is more tangible for human hearing. Each octave is represented with the same number of samples, so low frequencies are more readable. Frequency (=0) shows one sample for a fixed number of Hz, which is what the raw FFT gives, but most of the upper samples are uninteresting. Your ears hear ranges of octaves better.  IMPORTANT NOTE: If Mode is set to Visualization and this parameter is set to 0, the output data is interpreted more simply: 1 sample per Hz. Set the  viewer Units to Samples (via RMB on  graph) and the level you see at sample 5000 is the level at 5 KHz.\n\n\n\t\t\n  highfreqboost - When 0, the levels are not changed. When greater than 1, the levels are boosted, mostly at the high frequencies. High Frequency Boost can be over-driven past 1.\n\n\n\t\t\n  outputmenu -  - The method how output length will be determined.\n\n matchtofrequency - setmanually -\n\t\t\n  outlength - Number of Samples desired in output. The fewer the samples, the less the frequency resolution.\n\n\n\n\n\n  timeslice - Turning this on forces the channels to be \"Time Sliced\".  A  is the time between the last cook frame and the current cook frame.\n\n\n\n  scope - To determine which channels get affected, some CHOPs use a  string on the Common page. See Pattern Matching.\n\n\n\n  srselect -  - Handle cases where multiple input CHOPs' sample rates are different. When Resampling occurs, the curves are interpolated according to the Interpolation Method Option, or \"Linear\" if the Interpolate Options are not available.\n\n first - Use rate of first input to resample others. max - Resample to the highest sample rate. min - Resample to the lowest sample rate. err - Doesn't accept conflicting sample rates.\n\n  exportmethod -  - This will determine how to connect the  channel to the parameter. Refer to the Export article for more information.\n\n datindex - Uses the docked  table and references the channel via the index of the channel in the . datname - Uses the docked  table and references the channel via the name of the channel in the . autoname - The channel is the full destination of where to export to, such has geo1/transform1:tx.\n\n  autoexportroot - This path points to the root node where all of the paths that exporting by Channel Name is : are relative to.\n\n\n\n  exporttable - The  used to hold the export information when using the  Table  Methods (See above).\n\n\n\n\n\nA reasonable scenario (in terms of CPU usage) is an FFT size of 2048. You get good definition with the spectrum, and also enough padding to (almost) deal with two dropped frames.\nAn Info CHOP can be attached and the channel hz_per_sample can be viewed. Applicable only of the Frequency axis is set to Linear.\nWith it set to output to normal FFT, to determine the frequency that a given sample represents, use the formula:\nIn order to convert back to a signal, both channels are required. The suffixes should be the same as those used in the previous Audio Spectrum .\n\n\n -\n\nExtra Information for the Audio Spectrum  can be accessed via an Info CHOP.\n\n\n -\n - Start of the  interval in samples. - Number of samples in the . - The samplerate of the channels in frames per second. - Number of channels in the . - 1 if  is  enabled, 0 otherwise. - A count of how often the export connections have been updated.\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\n2022.241402021.100002018.28070before 2018.28070\nCHOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\nA Time Slice is the time from the last cook frame to the current cook frame. In CHOPs it is the set of short channels that contain the CHOP channels' samples between the last and the current cook frame.\n\n\n\nA parameter in most CHOPs that restricts which channels of that CHOP will be affected. Normally all channels of a CHOP are affected by the operator. TOPs have Channel Mask, a similar feature.\n\n\n\nsamples-per-second of a CHOP. Each CHOP in your network has a sample rate. In contrast, the overall timeline has a Frame Rate, which is the number of frames to cook and display per second, generally your monitor display frequency, default 60.\n\n\n\nExporting is the connection of CHOP channels to parameters of operators. The output of each exporting CHOP is one or more channels, active only while the CHOP Viewer is on. The current value of a channel can be exported to a parameter of any operator, overriding that parameter's value. See Parameter.\n\n\n\nAn Operator Family that manipulates text strings: multi-line text or tables. Multi-line text is often a python Script or GLSL Shader, but can be any multi-line text. Tables are rows and columns of cells, each containing a text string.\n\n\n\nThe location of an operator within the TouchDesigner environment, for example, /geo1/circle1, a node called circle1 in a component called geo1. The path / is called Root. This path is displayed at the top of every Pane, showing which Component's network you are currently in. To refer instead to a filesystem folder, directory, disk file or http: address, see Folder.\n\n\n\nEvery operator in TouchDesigner has a set of control Parameters that can be integer or floating point numbers, menus, binary toggles, text strings or operator paths, which determine the output of the operator.\n\n\n\nTouchDesigner is a hierarchy of components. \"root\" is the top-most network in the hierarchy. The Network Path or Path for root is simply /. A typical path is /project1/moviein1.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=Audio_Spectrum_CHOP&oldid=24443\"\n\t\tCategory: CHOPs",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.123Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Mode",
      "label": "Mode",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "The Audio Spectrum  calculates and displays the frequency spectrum of the input channels. \t\t\nIn the default Visualization Mode the  is set to display the spectrum in a more understandable way by emphasizing the higher frequency levels and the lower frequency ranges.\t\t\t\nIn another Mode, the Time to Magnitude and Phase mode, the audio can be converted to the frequency spectrum domain, manipulated and then converted back to get a filtered audio signal. When converting a signal to its spectrum, two channels are created from the one containing the audio signal. One channel contains the magnitude of the frequency components, and the other contains the phase. The channels are named, for example chan1_m and chan1_p where _m and _p are the suffixes for the magnitude and phase channels.\t\t\t\nTip:  You can reduce cook time if you decrease the FFT Size from its default 8192 samples. The fastest form of this  is by setting the Output Length parameter to \"Output Length Manually\". For example set the output buffer size to 2048 samples and the FFT Size to 2048. Each time it cooks, the  is looking at the latest 2028 samples (at 44.1 KHz that amounts to the 50 msec, or 3 frames), which is plenty. Note the default form of the  gives you 22,000 samples: 1 Hz to 22,050 Hz in steps of 1 Hz (when set to Frequency vs Logarithmic scaling), designed for clear interpretation: sample 1000 is the level of audio at 1000 Hz.\t\nTip:  To find the exact frequency of a wave entering the Audio Spectrum , look at the Info pop-up for that node (MMB on the node). It says:  Set \"Frequency <-> Logarithmic Scaling\" to 0, then multiply any sample to xxxx to get the Frequency at that sample.  xxxx depends on the sample rates etc and isn't a constant.\nSee Audio Filter CHOP, Audio Para EQ CHOP, Audio Band EQ CHOP, Audio Oscillator CHOP set to White Noise.\naudiospectrumCHOP_Class\n\nContents\n \n \n \n \n \n \n \n \n \n\n\n\n\n\n  mode -  - Select which mode to use, modes described below.\n\n visual - Show the spectrum in a way that more useful, with (by default) high frequencies boosted in level, and lower frequencies boosted in horizontal range. timetoraw - Calculate the frequency spectrum assuming input is a signal. rawtotime - Reconstructs a signal assuming input is a frequency spectrum similar to that coming from and Audio Spectum  set to the above option.\n\t\t\n  fftsize -  - Converting to frequency needs a power-of-2 number of samples, like 512, 1024, 2048. (FFT means Fast Fourier Transform.) The more samples, the more accurate the spectrum but the more it doesn't represent the most recent sound. Whatever the size, the  uses the most recent samples. Knowing that audio at 44100 samples per second with a timeline frame rate of 60 frames per second gives 735 samples per frame, if the  cooks 1 frame later and the FFT size is 1024, then it will re-use 1024-735 = 289 samples, which is good as there's a little overlap. However if it cooks 2 frames later, it will miss using 446 frames since it will have advanced 735*2=1470 samples and it will only use 1024 of them.\n\n 64 - 128 - 256 - 512 - 1024 - 2048 - 4096 - 8192 - 16384 -\n\t\t\n  frequencylog - Logarithmic (=1) is more tangible for human hearing. Each octave is represented with the same number of samples, so low frequencies are more readable. Frequency (=0) shows one sample for a fixed number of Hz, which is what the raw FFT gives, but most of the upper samples are uninteresting. Your ears hear ranges of octaves better.  IMPORTANT NOTE: If Mode is set to Visualization and this parameter is set to 0, the output data is interpreted more simply: 1 sample per Hz. Set the  viewer Units to Samples (via RMB on  graph) and the level you see at sample 5000 is the level at 5 KHz.\n\n\n\t\t\n  highfreqboost - When 0, the levels are not changed. When greater than 1, the levels are boosted, mostly at the high frequencies. High Frequency Boost can be over-driven past 1.\n\n\n\t\t\n  outputmenu -  - The method how output length will be determined.\n\n matchtofrequency - setmanually -\n\t\t\n  outlength - Number of Samples desired in output. The fewer the samples, the less the frequency resolution.\n\n\n\n\n\n  timeslice - Turning this on forces the channels to be \"Time Sliced\".  A  is the time between the last cook frame and the current cook frame.\n\n\n\n  scope - To determine which channels get affected, some CHOPs use a  string on the Common page. See Pattern Matching.\n\n\n\n  srselect -  - Handle cases where multiple input CHOPs' sample rates are different. When Resampling occurs, the curves are interpolated according to the Interpolation Method Option, or \"Linear\" if the Interpolate Options are not available.\n\n first - Use rate of first input to resample others. max - Resample to the highest sample rate. min - Resample to the lowest sample rate. err - Doesn't accept conflicting sample rates.\n\n  exportmethod -  - This will determine how to connect the  channel to the parameter. Refer to the Export article for more information.\n\n datindex - Uses the docked  table and references the channel via the index of the channel in the . datname - Uses the docked  table and references the channel via the name of the channel in the . autoname - The channel is the full destination of where to export to, such has geo1/transform1:tx.\n\n  autoexportroot - This path points to the root node where all of the paths that exporting by Channel Name is : are relative to.\n\n\n\n  exporttable - The  used to hold the export information when using the  Table  Methods (See above).\n\n\n\n\n\nA reasonable scenario (in terms of CPU usage) is an FFT size of 2048. You get good definition with the spectrum, and also enough padding to (almost) deal with two dropped frames.\nAn Info CHOP can be attached and the channel hz_per_sample can be viewed. Applicable only of the Frequency axis is set to Linear.\nWith it set to output to normal FFT, to determine the frequency that a given sample represents, use the formula:\nIn order to convert back to a signal, both channels are required. The suffixes should be the same as those used in the previous Audio Spectrum .\n\n\n -\n\nExtra Information for the Audio Spectrum  can be accessed via an Info CHOP.\n\n\n -\n - Start of the  interval in samples. - Number of samples in the . - The samplerate of the channels in frames per second. - Number of channels in the . - 1 if  is  enabled, 0 otherwise. - A count of how often the export connections have been updated.\n - Number of times the operator has cooked since the process started. - Duration of the last cook in milliseconds. - Frame number when this operator was last cooked relative to the component timeline. - Frame number when this operator was last cooked relative to the absolute time. - Time in milliseconds at which the operator started cooking in the frame it was cooked. - Time in milliseconds at which the operator finished cooking in the frame it was cooked. - 1 if operator was cooked this frame. - Number of warnings in this operator if any. - Number of errors in this operator if any.\nTouchDesigner Build: Latest\\n2022.241402021.100002018.28070before 2018.28070\nCHOPs\n• • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • \n\nAn Operator Family which operate on Channels (a sequence of numbers (Samples)) which are used for animation, audio, mathematics, simulation, logic, UI construction, and data streamed from/to devices and protocols.\n\n\n\nA Time Slice is the time from the last cook frame to the current cook frame. In CHOPs it is the set of short channels that contain the CHOP channels' samples between the last and the current cook frame.\n\n\n\nA parameter in most CHOPs that restricts which channels of that CHOP will be affected. Normally all channels of a CHOP are affected by the operator. TOPs have Channel Mask, a similar feature.\n\n\n\nsamples-per-second of a CHOP. Each CHOP in your network has a sample rate. In contrast, the overall timeline has a Frame Rate, which is the number of frames to cook and display per second, generally your monitor display frequency, default 60.\n\n\n\nExporting is the connection of CHOP channels to parameters of operators. The output of each exporting CHOP is one or more channels, active only while the CHOP Viewer is on. The current value of a channel can be exported to a parameter of any operator, overriding that parameter's value. See Parameter.\n\n\n\nAn Operator Family that manipulates text strings: multi-line text or tables. Multi-line text is often a python Script or GLSL Shader, but can be any multi-line text. Tables are rows and columns of cells, each containing a text string.\n\n\n\nThe location of an operator within the TouchDesigner environment, for example, /geo1/circle1, a node called circle1 in a component called geo1. The path / is called Root. This path is displayed at the top of every Pane, showing which Component's network you are currently in. To refer instead to a filesystem folder, directory, disk file or http: address, see Folder.\n\n\n\nEvery operator in TouchDesigner has a set of control Parameters that can be integer or floating point numbers, menus, binary toggles, text strings or operator paths, which determine the output of the operator.\n\n\n\nTouchDesigner is a hierarchy of components. \"root\" is the top-most network in the hierarchy. The Network Path or Path for root is simply /. A typical path is /project1/moviein1.\n\n\n\n\n\n\n\n\nRetrieved from \"https://docs.derivative.ca/index.php?title=Audio_Spectrum_CHOP&oldid=24443\"",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Mode",
      "label": "Mode",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "mode -  - Select which mode to use, modes described below.\n\n visual - Show the spectrum in a way that more useful, with (by default) high frequencies boosted in level, and lower frequencies boosted in horizontal range. timetoraw - Calculate the frequency spectrum assuming input is a signal. rawtotime - Reconstructs a signal assuming input is a frequency spectrum similar to that coming from and Audio Spectum  set to the above option.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Visualization",
      "label": "Visualization",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "visual - Show the spectrum in a way that more useful, with (by default) high frequencies boosted in level, and lower frequencies boosted in horizontal range. timetoraw - Calculate the frequency spectrum assuming input is a signal. rawtotime - Reconstructs a signal assuming input is a frequency spectrum similar to that coming from and Audio Spectum  set to the above option.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "FFT Size",
      "label": "FFT Size",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "fftsize -  - Converting to frequency needs a power-of-2 number of samples, like 512, 1024, 2048. (FFT means Fast Fourier Transform.) The more samples, the more accurate the spectrum but the more it doesn't represent the most recent sound. Whatever the size, the  uses the most recent samples. Knowing that audio at 44100 samples per second with a timeline frame rate of 60 frames per second gives 735 samples per frame, if the  cooks 1 frame later and the FFT size is 1024, then it will re-use 1024-735 = 289 samples, which is good as there's a little overlap. However if it cooks 2 frames later, it will miss using 446 frames since it will have advanced 735*2=1470 samples and it will only use 1024 of them.\n\n 64 - 128 - 256 - 512 - 1024 - 2048 - 4096 - 8192 - 16384 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "64",
      "label": "64",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "64 - 128 - 256 - 512 - 1024 - 2048 - 4096 - 8192 - 16384 -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Frequency <-> Logarithmic Scaling",
      "label": "Frequency <-> Logarithmic Scaling",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "frequencylog - Logarithmic (=1) is more tangible for human hearing. Each octave is represented with the same number of samples, so low frequencies are more readable. Frequency (=0) shows one sample for a fixed number of Hz, which is what the raw FFT gives, but most of the upper samples are uninteresting. Your ears hear ranges of octaves better.  IMPORTANT NOTE: If Mode is set to Visualization and this parameter is set to 0, the output data is interpreted more simply: 1 sample per Hz. Set the  viewer Units to Samples (via RMB on  graph) and the level you see at sample 5000 is the level at 5 KHz.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "High Frequency Boost",
      "label": "High Frequency Boost",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "highfreqboost - When 0, the levels are not changed. When greater than 1, the levels are boosted, mostly at the high frequencies. High Frequency Boost can be over-driven past 1.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Output Length",
      "label": "Output Length",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "outputmenu -  - The method how output length will be determined.\n\n matchtofrequency - setmanually -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Match Length To Frequency",
      "label": "Match Length To Frequency",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "matchtofrequency - setmanually -",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Set Output Length",
      "label": "Set Output Length",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "outlength - Number of Samples desired in output. The fewer the samples, the less the frequency resolution.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Time Slice",
      "label": "Time Slice",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "timeslice - Turning this on forces the channels to be \"Time Sliced\".  A  is the time between the last cook frame and the current cook frame.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Scope",
      "label": "Scope",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "scope - To determine which channels get affected, some CHOPs use a  string on the Common page. See Pattern Matching.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Sample Rate Match",
      "label": "Sample Rate Match",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "srselect -  - Handle cases where multiple input CHOPs' sample rates are different. When Resampling occurs, the curves are interpolated according to the Interpolation Method Option, or \"Linear\" if the Interpolate Options are not available.\n\n first - Use rate of first input to resample others. max - Resample to the highest sample rate. min - Resample to the lowest sample rate. err - Doesn't accept conflicting sample rates.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.125Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Resample At First Input's Rate",
      "label": "Resample At First Input's Rate",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "first - Use rate of first input to resample others. max - Resample to the highest sample rate. min - Resample to the lowest sample rate. err - Doesn't accept conflicting sample rates.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.126Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Export Method",
      "label": "Export Method",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "exportmethod -  - This will determine how to connect the  channel to the parameter. Refer to the Export article for more information.\n\n datindex - Uses the docked  table and references the channel via the index of the channel in the . datname - Uses the docked  table and references the channel via the name of the channel in the . autoname - The channel is the full destination of where to export to, such has geo1/transform1:tx.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.126Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "DAT Table by Index",
      "label": "DAT Table by Index",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "datindex - Uses the docked  table and references the channel via the index of the channel in the . datname - Uses the docked  table and references the channel via the name of the channel in the . autoname - The channel is the full destination of where to export to, such has geo1/transform1:tx.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.126Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Export Root",
      "label": "Export Root",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "autoexportroot - This path points to the root node where all of the paths that exporting by Channel Name is : are relative to.",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.126Z",
      "rawData": {},
      "sourceElement": null
    },
    {
      "id": null,
      "name": "Export Table",
      "label": "Export Table",
      "group": "General",
      "page": "",
      "type": "float",
      "dataType": "number",
      "style": "",
      "defaultValue": null,
      "minValue": null,
      "maxValue": null,
      "step": null,
      "menuItems": [],
      "menuLabels": [],
      "allowCustom": false,
      "maxLength": null,
      "pattern": null,
      "isArray": false,
      "arraySize": 1,
      "dimensions": 1,
      "description": "exporttable - The  used to hold the export information when using the  Table  Methods (See above).",
      "tooltip": "",
      "help": "",
      "units": "",
      "examples": [],
      "isReadOnly": false,
      "isAdvanced": false,
      "isHidden": false,
      "isAnimatable": true,
      "isExpression": false,
      "isPython": false,
      "dependsOn": [],
      "affects": [],
      "linkedTo": [],
      "expressionLanguage": "",
      "defaultExpression": "",
      "commonExpressions": [],
      "order": 0,
      "isVisible": true,
      "conditionalDisplay": null,
      "isValid": true,
      "validationErrors": [],
      "lastUpdated": "2025-08-07T07:49:57.126Z",
      "rawData": {},
      "sourceElement": null
    }
  ],
  "parameterGroups": {},
  "codeExamples": [],
  "pythonExamples": [],
  "expressions": [],
  "commonInputs": [],
  "commonOutputs": [],
  "relatedOperators": [],
  "workflowPatterns": [],
  "images": [],
  "videos": [],
  "assets": [],
  "keywords": [
    "audio",
    "spectrum",
    "chop",
    "calculates",
    "displays",
    "frequency",
    "input",
    "channels."
  ],
  "tags": [
    "CHOP",
    "TouchDesigner",
    "Audio Spectrum CHOP"
  ],
  "searchWeight": 1,
  "contentHash": "",
  "processingDate": "2025-08-07T07:49:57.127Z",
  "processingVersion": "1.0.0",
  "isValid": true,
  "validationErrors": []
}